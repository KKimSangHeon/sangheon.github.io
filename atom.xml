<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kim Sang Heon&#39;s Bolg</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://KKimSangHeon.github.io/"/>
  <updated>2019-06-09T08:22:05.710Z</updated>
  <id>http://KKimSangHeon.github.io/</id>
  
  <author>
    <name>Kim Sang Heon</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MSA이론4. DevOps</title>
    <link href="http://KKimSangHeon.github.io/2019/06/08/msa4/"/>
    <id>http://KKimSangHeon.github.io/2019/06/08/msa4/</id>
    <published>2019-06-08T05:19:44.000Z</published>
    <updated>2019-06-09T08:22:05.710Z</updated>
    
    <content type="html"><![CDATA[<h3 id="DevOps"><a href="#DevOps" class="headerlink" title="DevOps"></a>DevOps</h3><p>Using DevOps to Solve your Delivery Challenges</p>
<ul>
<li>배포는 너무 오래걸린다.</li>
<li>테스트에 대해 혼란스럽다.</li>
<li>특정 개인에 대한 높은 의존성.</li>
<li>데브옵스 모델은 lock을 제거한다.</li>
<li>데브옵스 모델은 프로비저닝한다.</li>
</ul>
<p><code>Delivery는 Continuous integration + continuous deployment를 의미한다.</code></p>
<h4 id="데프옵스의-특징"><a href="#데프옵스의-특징" class="headerlink" title="데프옵스의 특징"></a>데프옵스의 특징</h4><ul>
<li>높은신뢰성, 높은 퍼포먼스</li>
<li>데브옵스는 프로덕트, 툴이아니다. 데브옵스는 문화이다.</li>
<li>고수준의 자동화 프로세스</li>
<li>정기적이고 반복적인 플로우를 따른다. 싸이클은 짧고, 작고 잦은 변경을 선호한다.</li>
</ul>
<h4 id="DevOps-1"><a href="#DevOps-1" class="headerlink" title="DevOps"></a>DevOps</h4><ul>
<li>데브옵스의 철학은 개발과 운영의 통합 문화를 만들고, 협업 변화를 촉진하기 위해 기술의 linked toolchain 을 요구하는 것이다.<br><code>toolchain?</code> : Target 시스템의 Software 개발을 진행하기 위해 필요한 host system의 Cross Compile(교차 컴파일) 환경이다.</li>
<li>DevOps의 toolchain은 수십개의 non-collaborative 툴을 포함할 수 있고, 복잡하고 어려운 작업을 자동화를 통해 task로 만들 수 있다.</li>
<li>DepOps의 정의에 따르면 one-size-fits-all이 해결책이 아니다.</li>
<li>DevOps는 특정 문제 및 과제에 대한 정보를 제공한다.</li>
</ul>
<h4 id="DevOps를-위한-microservice-requirements"><a href="#DevOps를-위한-microservice-requirements" class="headerlink" title="DevOps를 위한 microservice requirements"></a>DevOps를 위한 microservice requirements</h4><ul>
<li>microservice에 기반한 새로운 어플리케이션을 빌드하라</li>
<li>기존 microservice 어플리케이션을 클라우드로 마이그레이션하라</li>
<li>하이브리드 microservice 어플리케이션을 배포하라</li>
<li>존재하는 어플리케이션들을 microservice architecture로 발전하라.</li>
</ul>
<h4 id="Microservice-배포를-위해-따라야-할-Roles"><a href="#Microservice-배포를-위해-따라야-할-Roles" class="headerlink" title="Microservice 배포를 위해 따라야 할 Roles"></a>Microservice 배포를 위해 따라야 할 Roles</h4><ul>
<li>개발자는 테스트를 반복하며 각 테스트는 pass해야한다. 또한 계속되는 피드백에 대비하자.</li>
<li>테스터는 자동화 된 파이프라인에 컴포넌트, 통합, 회귀를 포함하고 크로스 플랫폼간 API를 통해 테스트가 가능토록 하자.</li>
<li>성능테스터는 로딩 테스팅을 모니터링하고 blue/green, rolling 배포를 하자.</li>
</ul>
<p><code>rolling 배포:</code>일반적인 배포를 의미하는데, 단순하게 한 대씩 재시작한다. 코드 변경에 따른 side effect가 발생할 수 있다<br><code>blue-green 배포:</code> 예전 배포물을 블루(blue), 신규 배포물을 그린(green)이라고 해서 붙여진 이름이다. 새로운 배포물을 배포하고 모든 연결을 새로운 배포물만 보게 하며 코드 변경에 따른 side effect가 없다. (배포시 중단시점이 없음!)</p>
<ul>
<li>Release 하는사람은 성능 측정을 해야한다.</li>
<li>운영자는 가용성을 모니터링하고 blue/green 배포를 해야한다.</li>
<li>엔드유저는 지속적인 피드백을 주고 변경에 대해 대비한다.</li>
</ul>
<h4 id="DevOps의-평가기준"><a href="#DevOps의-평가기준" class="headerlink" title="DevOps의 평가기준"></a>DevOps의 평가기준</h4><p>배포빈도(얼마나 자주 배포하나)</p>
<ul>
<li>최상: 요구될때마다</li>
<li>보통: 일주일 혹은 한달에 한번</li>
<li>최하: 한달에서 여섯달 사이에 한번</li>
</ul>
<p>Lead time for changes(ie.코드가 커밋되고 정상적으로 동작하는데 걸리는 시간)</p>
<ul>
<li>최상: 한시간 이내</li>
<li>보통: 일주일 ~ 한달사이</li>
<li>최하: 한달~여섯달 사이</li>
</ul>
<p>Mean time to recover(복구하는데 걸리는 시간)</p>
<ul>
<li>최상: 한시간 이내</li>
<li>보통: 하루 이상</li>
<li>최하: 하루 이상</li>
</ul>
<p>Change failure rate</p>
<ul>
<li>최상: 0~15%</li>
<li>보통: 31~45%</li>
<li>최하: 16~30%</li>
</ul>
<h4 id="Database-관련-생각해봐야-할것들"><a href="#Database-관련-생각해봐야-할것들" class="headerlink" title="Database 관련 생각해봐야 할것들"></a>Database 관련 생각해봐야 할것들</h4><ul>
<li>Production data에 대한 보호,보안(바꾸는 것은 리스크가 있다)</li>
<li>Test data 필요</li>
<li>환경이 다름</li>
<li>의존성</li>
<li>다수 어플리케이션이 동일 db에 접근한다.</li>
<li>이전버전과 호환성 유지</li>
<li>롤백을 어떻게 할지</li>
</ul>
<h4 id="DevOps-Values"><a href="#DevOps-Values" class="headerlink" title="DevOps Values"></a>DevOps Values</h4><p>CALMS</p>
<ul>
<li>Culture - 변화를 수용하라</li>
<li>Automation - CI/CD</li>
<li>Lean - 엔드유저가 생상하는 value에 초점을 맞추고, 배치사이즈를 작게하라</li>
<li>Measurement - 모든것을 측정하고 개선된것을 보여줘라</li>
<li>Sharing - 정보를 공유하고 협업하라</li>
</ul>
<h4 id="DevOps-Tools"><a href="#DevOps-Tools" class="headerlink" title="DevOps Tools"></a>DevOps Tools</h4><p><code>Configuration Automation / Management:</code> Puppet, Ansible, Chef, Salt<br><code>Continuous Integration:</code>Jenkins, CruiseControl, Capistrano<br><code>Monitoring:</code>Icinga (nagios), Zenoss, Sweet, Graphite<br><code>Containerization:</code> Docker, Rocket</p>
<h4 id="DevOps-관련용어"><a href="#DevOps-관련용어" class="headerlink" title="DevOps 관련용어"></a>DevOps 관련용어</h4><p>CI/CD</p>
<ul>
<li>Continuous Integration 그리고 Continuous Deployment의 약어</li>
</ul>
<p>Continuous integration</p>
<ul>
<li>최신코드에서 변경된것을 사용가능하도록 빌드한다.</li>
</ul>
<p>Continuous deployment</p>
<ul>
<li>가능한 빠르게 배포 단계를 거치고 빌드된 해당 패키지가 프로덕션 환경으로 전환되도록 한다.</li>
</ul>
<p>Continuous delivery</p>
<ul>
<li>Continuous integration + continuous deployment</li>
</ul>
<p>Delivery pipeline</p>
<ul>
<li>일련의 자동화 단계로써 CI/CD를 수행한다.</li>
</ul>
<h4 id="Continuous-Integration"><a href="#Continuous-Integration" class="headerlink" title="Continuous Integration"></a>Continuous Integration</h4><p>아래와 같은 단계를 빈번하게 수행한다.</p>
<p><code>1. Development</code></p>
<ul>
<li>배치 테스를 거친 작은 변화들이 빠르게 구현된다.</li>
</ul>
<p><code>2. SCM(Source Code management)</code></p>
<ul>
<li>여러 개발자의 변경된것사항을 병합한다.(GitHub, SVN … 활용)</li>
</ul>
<p><code>3. Build</code></p>
<ul>
<li>배포할것을 만든다.(Jenkins, Gradle, Maven …  활용)</li>
</ul>
<p><code>4. Package</code></p>
<ul>
<li>런타임때 빌드를 설치한다.</li>
<li>변경할 수 없는 이미지를 런타임때 releasing 한다.</li>
<li>클라우드에 푸쉬하고 컨테이너 이미지 빌드</li>
</ul>
<h4 id="Continuous-integration-–-package-step"><a href="#Continuous-integration-–-package-step" class="headerlink" title="Continuous integration – package step"></a>Continuous integration – package step</h4><p>package step에선 변경 불가능한 이미지가 만들어진다. 이는 deploying instance를 생성할 때 사용된다. 이미지를 변경하고 싶다면 삭제하고 새로 만들어야 한다.</p>
<h4 id="Continuous-Deployment"><a href="#Continuous-Deployment" class="headerlink" title="Continuous Deployment"></a>Continuous Deployment</h4><p>Production 배포까지의 과정<br><code>1. Deploy to Test</code></p>
<ul>
<li>functional testing 진행, test tool을 활용한 자동화<br><code>2. Deploy to Stage</code></li>
<li>Production 배포 전 리허설</li>
<li>통합 testing 진행<br><code>3. Deploy to Prod</code></li>
<li>사용자가 사용할 수 있도록 빌드</li>
</ul>
<h4 id="Continuous-Delivery-vs-continuous-Deployment"><a href="#Continuous-Delivery-vs-continuous-Deployment" class="headerlink" title="Continuous Delivery vs continuous Deployment"></a>Continuous Delivery vs continuous Deployment</h4><p>!!!!!!!!!!!!!!!!!!!!!!!!!!Continuous Delivery vs continuous Deployment<br></p>
<h4 id="Zero-Downtime-Deployment"><a href="#Zero-Downtime-Deployment" class="headerlink" title="Zero Downtime Deployment"></a>Zero Downtime Deployment</h4><p>서비스 중단없이 새로운 버전을 배포하는것을 의미한다. DevOps는 잦은 배포를 하므로 필요하다.</p>
<h4 id="Zero-Downtime-Deployment-특징"><a href="#Zero-Downtime-Deployment-특징" class="headerlink" title="Zero Downtime Deployment 특징"></a>Zero Downtime Deployment 특징</h4><ul>
<li>어플리케이션은 항상 사용가능하다.</li>
<li>사용자가 중단(Downtime)없이 사용할 수 있다.</li>
<li>이전버전, 새버전이 동시에 배포됨 - 트래픽이 둘 다로 전달됨.</li>
</ul>
<h4 id="Implementing-Zero-Downtime-Deployment-–-Blue-Green"><a href="#Implementing-Zero-Downtime-Deployment-–-Blue-Green" class="headerlink" title="Implementing Zero Downtime Deployment – Blue Green"></a>Implementing Zero Downtime Deployment – Blue Green</h4><p>Deployment<br>필요한경우 이전버전으로 신성하게 되돌릴 수 있다.</p>
<p>1.v1(blue)이 배포되어 사용자들이 사용하고 있을 때  v2(green)을 배포한다.<br>2.자동화된 테스트 도구로 테스트, 검증을 진행하고 사용자를 v1에서 v2환경으로 변환한다.<br>3.v1(blue)을 삭제한다.</p>
<h4 id="DevOps로의-Transformation"><a href="#DevOps로의-Transformation" class="headerlink" title="DevOps로의 Transformation"></a>DevOps로의 Transformation</h4><ul>
<li>Top to Bottom문화를 변화시키는 것이 핵심이다.</li>
<li>교육을 늘리고 커뮤니케이션하고 cross-skilling 하라</li>
<li>DevOps가 가능한 새로운 프로세스를 평가하라</li>
<li>스스로 재평가하고 재빌드하라</li>
<li>DevOps를 지원하는 새로운 기술 평가</li>
<li>조직을 작게 나눠라</li>
</ul>
<h4 id="Bottom-Up-Implementation"><a href="#Bottom-Up-Implementation" class="headerlink" title="Bottom-Up Implementation"></a>Bottom-Up Implementation</h4><ul>
<li>협업을 위한 방법을 찾아라. (사람들을 초기부터 참가시킨다.)</li>
<li>자동화 방법을 찾아라</li>
<li>metrics driven이 되어라</li>
<li>새로운것을 배우고 지속적으로 개선해라</li>
<li>작은 batches와 함께 병렬적으로 일해라</li>
<li>리팩토링을 허락해라</li>
<li>경영진에게 비즈니스 가치를 입증해라</li>
<li>비즈니스의 목표, metrics, 우선순위를 이해하라.</li>
</ul>
<h4 id="Top-Down-Implementation"><a href="#Top-Down-Implementation" class="headerlink" title="Top-Down Implementation"></a>Top-Down Implementation</h4><ul>
<li>시험 케이스를 파일럿으로 선택하라</li>
<li>우수 사레를 문서화하고 전파하라</li>
<li>팀의 역량을 강화하고 가치를 이끌어내라</li>
<li>측정 가능한 결과를 요구하라</li>
<li>과거의 baseline이 충분치 않을때 변명하지 마라</li>
<li>빠르게 실패하고 지속적으로 향상하라</li>
<li>작은성공을 기반으로 나아가라</li>
<li>비효율적인 경우 그룹간 역할 및 책임을 조율하라.</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;DevOps&quot;&gt;&lt;a href=&quot;#DevOps&quot; class=&quot;headerlink&quot; title=&quot;DevOps&quot;&gt;&lt;/a&gt;DevOps&lt;/h3&gt;&lt;p&gt;Using DevOps to Solve your Delivery Challenges&lt;/p&gt;
&lt;ul
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/tags/MSA/"/>
    
  </entry>
  
  <entry>
    <title>MSA이론3. Database Design for Microservices</title>
    <link href="http://KKimSangHeon.github.io/2019/06/08/msa3/"/>
    <id>http://KKimSangHeon.github.io/2019/06/08/msa3/</id>
    <published>2019-06-08T05:18:22.000Z</published>
    <updated>2019-06-09T08:22:01.910Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Database-Design-for-Microservices"><a href="#Database-Design-for-Microservices" class="headerlink" title="Database Design for Microservices"></a>Database Design for Microservices</h3><p>트랜잭션, Aggregates에 영향을 많이끼친다.</p>
<p>Front Microservice는 쉽다.</p>
<h4 id="ACID가-적용되는-것들"><a href="#ACID가-적용되는-것들" class="headerlink" title="ACID가 적용되는 것들"></a>ACID가 적용되는 것들</h4><p>Transaction, Aggregates, Entity</p>
<h3 id="ACID-vs-BASE"><a href="#ACID-vs-BASE" class="headerlink" title="ACID vs BASE"></a>ACID vs BASE</h3><p>ACID</p>
<ul>
<li>Atomicity, Consistency, Isolation, and Durability</li>
<li>Strong consistency</li>
<li>commit에 초점을 맞춘다.</li>
<li>보수적이다.(혁신이 어렵다)</li>
</ul>
<p>BASE</p>
<ul>
<li>Basically Available, Soft-state, Eventual consistency</li>
<li>Weak consistency</li>
<li>Availability first</li>
<li>간단하고 빠르다(혁신이 쉽다)</li>
</ul>
<h4 id="구현을-위해-생각해보자"><a href="#구현을-위해-생각해보자" class="headerlink" title="구현을 위해 생각해보자"></a>구현을 위해 생각해보자</h4><ul>
<li>마이크로서비스에서 데이터는 dependency를 갖기 때문에 어려운부분이다.</li>
<li>microservice에 각각의 db가 있을 때 어떻게 읽고 어떻게 업데이트할까? join활용</li>
<li>data inside, 서비스, data outside 를 이해할 필요가있다.</li>
<li>데이터를 어떻게 읽고 업데이트하는가?</li>
<li>읽고 쓰는 명령 쿼리를 분할한다.(CQRS, Command Query Responsibility Segregation)</li>
</ul>
<h4 id="Two-phase-commit"><a href="#Two-phase-commit" class="headerlink" title="Two-phase commit"></a>Two-phase commit</h4><p>모든 트랜잭션은 트랜잭션 관리자를 거쳐야 한다. 이는 모든 서비스에서 트랜잭션을 보장하며 커밋 요청, 커밋 두단계의 메커니즘을 거친다.</p>
<p>커밋요청단계(커밋 투표단계라고도 함) : 관리자가 모든 서비스에 커밋메세지 쿼리를 보낸다. 관리자는 모든 서비스의 투표 결과를 대기하고 각 서버는 커밋해야 할 지점까지 트랜잭션을 수행한다. 서비스는 일부가 준비되지 않아도 동의한다는 응답을 보낸다.</p>
<p>커밋단계(완료단계라고도 함)</p>
<ul>
<li>관리자가 모든 서비스에서 동의를 받았을 때: 관리자는 트랜잭션 커밋을 요청하는 메세지를 모든 서비스에게 전송한다. 커밋 후에 서비스는 트랜잭션이 끝났다는 확인을 관리자에게 보낸다.</li>
<li>관리자가 하나 이상의 거절을 받았을 때 : 관리자는 모든 서비스들에게 롤백을 요청하고 서비스는 롤백 후 관리자에게 승인응답을 보낸다.</li>
</ul>
<h4 id="Two-phase-commit-의-장점"><a href="#Two-phase-commit-의-장점" class="headerlink" title="Two-phase commit 의 장점"></a>Two-phase commit 의 장점</h4><p>많은 DB가 영향을 받을경우 이를 하나의 트랜잭션으로 다루는것이 좋다.<br>준비단계는 모든 구성요소가 커밋을 허용하는지 확인하는 단계이다.</p>
<h4 id="Two-phase-commit-의-단점"><a href="#Two-phase-commit-의-단점" class="headerlink" title="Two-phase commit 의 단점"></a>Two-phase commit 의 단점</h4><ul>
<li>관리자는 서비스에서 메세지를 수신할 때 까지 잠금이 걸려 리소스가 해제되지 않음.(가용성 측면)</li>
<li>서비스 중 하나가 커밋을 거부하면 모든 서비스가 롤백한다.(일관성을 유지할 수 있다는 장점)</li>
<li>서비스에서 응답을 수신할 때 까지 잠금,리소스가 해제되지 않음</li>
<li>NoSQL을 지원하지 않음.</li>
<li>최소 O(4n) 메세지 발생, 여러번시도할 경우 O(n^2)</li>
<li>lock으로 인한 처리량 감소</li>
</ul>
<h4 id="Distributed-Transactions-in-Microservices"><a href="#Distributed-Transactions-in-Microservices" class="headerlink" title="Distributed Transactions in Microservices"></a>Distributed Transactions in Microservices</h4>
<p>microservice에는 ACID를 적용하기가 복잡하다. 이는 microservice Architecture가  Single Responsibility Principle (SRP)를 따르므로 각 microservice가 해당 데이터를 유지하고 관리해야하고, microservice의 책임에 대한 지식없이는 다른서비의 데이터에 접근할 수 없기때문이다.</p>
<p>위 그림에서 두개의 microservice가 하나의 db에 연결되어있는게 왜 잘못되었을까? 우측의 경우에는 API, Queue로 해당 호출이 가능하다. 하지만 좌측의 경우에는 두개의 db 아답터가 가 존재해야 하는데 Isolation 원칙을 위배한다.</p>
<h4 id="Distributed-Transaction-–-Event-Driven-Architecture-amp-Two-Phase-Commit"><a href="#Distributed-Transaction-–-Event-Driven-Architecture-amp-Two-Phase-Commit" class="headerlink" title="Distributed Transaction – Event Driven Architecture &amp; Two Phase Commit"></a>Distributed Transaction – Event Driven Architecture &amp; Two Phase Commit</h4>
<ul>
<li>이는 가장 일관된 시스템을 제공하지만 Two Phase Commit으로 인해 시스템 성능에 부정적 영향을 끼친다.</li>
<li>이벤트는 트랜잭션의 매 단계를 실행시키는 트리거이며 각 이벤트는 고유한 ID를 갖는다. 또한 작업이 처리되었으면 커밋되었음을 나타내야 한다.</li>
</ul>

<p>위의 그림은 microservice1이 microservice2에 자동이체를 하는 트랜잭션이다.</p>
<ul>
<li>completed라는 컬럼은 트랜잭션이 커밋되어야 하는지를 나타내며 microservice1이 완료되면 microservice2를 호출하여 트랜잭션을 완료한다.(그림은 microservice1의 작업이 커밋되고 microservice2의 작업이 커밋되기 전 단계)</li>
</ul>
<h4 id="CAP-Theorem"><a href="#CAP-Theorem" class="headerlink" title="CAP Theorem"></a>CAP Theorem</h4>
<p>분산시스템에서는 일관성(Consistency), 가용성(Availability,항상 데이터를 읽고 쓸 수 있음), 분할 용인(Partition tolerance,데이터베이스를 분할할 수 있고 네트워크 중단에도 계속 동작할 수 있다.)이라는 세 가지 조건을 모두 만족할 수 없다. 대부분 세 조건중 두 가지만 만족시킬 수 있다.<br>만약 가용성을 만족시키려면 BASE(Basically available, soft state, eventually consistent)를 생각해 볼 수 있다. 이를 위해 앞서 설명한 Event Driven Architecture를 도입할 수 있다.<br><code>BASE</code> : 기본적으로 Availability하고, 사용자가 관리하지 않으면 데이터가 expire 될 수 있으며, 언젠가는 데이터가 일관성을 가진다는 것.</p>
<h4 id="Eventual-Consistency-and-Compensation"><a href="#Eventual-Consistency-and-Compensation" class="headerlink" title="Eventual Consistency and Compensation"></a>Eventual Consistency and Compensation</h4><ul>
<li>microservice에서 일관성을 다루는 것중 가장 실현 가능한것은 Eventual Consistency이다.</li>
<li>microservice에서 분산 ACID 트랜잭션을 사용하지 않는다. 대신 미래의 어떤시점에서는 시스템이 결국 일관성을 유지할것을 제안한다.</li>
<li>Eventual Consistency 서비스는 종종 BASE를 제공하는것으로 분류된다.</li>
<li>Eventual Consistency는 분산 소프트웨어의 복잡성을 증가시킨다고 비판받기도 하는데 이는 동일값을 읽는다는 안전보장을 하지 않기 때문에 발생한다(결국에는 읽었을 때 동일값을 반환 함 예시로 배치프로그램이 있음).</li>
</ul>
<h4 id="Eventual-Consistency의-예시"><a href="#Eventual-Consistency의-예시" class="headerlink" title="Eventual Consistency의 예시"></a>Eventual Consistency의 예시</h4><p>다음의 문제를 해결해야 된다고 가정해보자.</p>
<ul>
<li>user profile 등록</li>
<li>백그라운드에서는 사용자가 시스템에 접근할 수 있는지 자동으로 확인</li>
</ul>
<p>Eventual Consistenc 적용을 하려면..</p>
<ul>
<li>user의 접근 가능유무는 반드시 필요하다.</li>
<li>user검증 시간이 오래 걸리더라도 microservice로 분할해야한다.</li>
</ul>
<p>compensation을 포함한 message-driven방법 적용</p>
<ul>
<li>user profile을 등록하는 작업</li>
<li>백그라운드에서 유효성을 검사하는 microservice</li>
<li>지속적인 큐를 제공하는 메세지 플랫폼<br>(메세지 플랫폼은 microservice가 보낸 메세지가 지속가능토록 한다. 수신부가 문제가 있다면 나중에 배달해주기도 함)<br>-이는 하나의 microservice가 중지될 경우 정보는 다른 큐, 서비스에 존재한다. 즉 지속성을 보장한다.</li>
</ul>
<p>위의 방법을 적용했을 때 좋은 시나리오</p>
<ul>
<li>user microservice는 user를 등록하고 로컬 db에 정보를 저장한다.</li>
<li>user microservice는 플래그를 활용해 해당 user가 검증 과정을 거치지 않음을 표시한다.</li>
<li>user에게 지금 당장은 접근 불가능하다는 경고를 보낸다.</li>
<li>user microservice는 백그라운드에서 user검증을 위해 validation microservice에 메세지를 보낸다.</li>
<li>검증결과 접근가능하다면 user microservice는 user를 unblock한다/ 검증결과 접근 불가능하다면 user microservice는 user 계정을 제거한다. (이를 compensation(보상)단계라고 볼 수 있다.)</li>
</ul>
<p>일련의 과정을 거친후에는 시스템은 일관된 상태이다. 하지만 일정기간동안은 사용자 엔티티가 불완전한 상태였다.</p>
<p>위의 방법을 적용했을 때 좋지 않은 시나리오</p>
<ul>
<li>validation microservice에 접근할수 없는경우 메세지 플랫폼은 나중에 validation microservice가 접근 가능하게 되었을 때 validation microservice는 메세지를 받아볼 수 있다.</li>
<li>메세지 플랫폼에 문제가 발생하면 user microservice는 또 다시 다른 user의 검증 메세지를 보낸다.</li>
<li>validation microservice가 메세지를 받게되면 user를 검증하지만 메세지 플랫폼 문제가 발생하면 응답을 보내지 못하고 추 후 다시 보낸다.</li>
</ul>
<p>그러나 일부메세지가 여러번 발행되더라도 데이터 일관성에는 영향을 미치지 않는다.<br>발생할 수 있는 좋지 않은 시나리오들을 고려함으로써 Eventual Consistency를 충족시킬 수 있으며 비용소모가 심한  distributed transactions를 처리할 필요가 없다.</p>
<h4 id="Distributed-Transactions-The-Solution"><a href="#Distributed-Transactions-The-Solution" class="headerlink" title="Distributed Transactions: The Solution"></a>Distributed Transactions: The Solution</h4><p>결제하고 배송하는 시스템을 Distributed Transaction방식으로 구현한다고 해보자<br></p>
<p>위와 같은 방식으로 할 수 있으나 일련의 과정은 동기방식이다.<br>이를 비동기 방식으로 처리하기 위해 아래와 같은 방식을 따르면 된다. 즉 쓰레드를 하나 만들어서 처리한다.</p>

<p>안전한 Distributed Transactions를 위해서</p>
<ul>
<li>원격 업데이트에 대한 영향 감수</li>
<li>원격 업데이트를 시도하고 응답을 받지 못했을 경우 재시도를 해야한다. 또한 응답이 오더라도 자체 대기열을 업데이트하지 못할 경우 대기열이 사용가능해지면 다시 시도해서 업데이트 해야한다.</li>
<li>재시도로 발생하는 중복수신은한번만 처리한다</li>
<li>하나의 작업단위를 완료하더라도 시스템 오류가 발생하면 동기화 되지 않을 수 있다.</li>
<li>이를통해볼 때 microservice는 Distributed 트랜잭션에 호의적이지 않다.</li>
</ul>
<p>동기관련 문제를 해결할 수 있는 메세지 브로커<br></p>
<h4 id="Two-Consequences-of-Eventual-Consistency"><a href="#Two-Consequences-of-Eventual-Consistency" class="headerlink" title="Two Consequences of Eventual Consistency"></a>Two Consequences of Eventual Consistency</h4><ul>
<li>재시도를 하는것은 시스템에 문제가 생긴것을 의미한다.</li>
<li>일관성이 결국에는 생기는것이기 때문에 비즈니스 일관성이 충돌하는 경우도 있을 수 있다.<br>만약 책을 구매하는 비즈니스가 있다고 할 때 결제를 하는순간 재고가 있어 결제가 진행되었는데 결제가 완료되는 순간 재고가 없을 때를 가정해보자. 이 때는 비동기식으로 사용자에게 다시 보고하지 않고 환불절차를 진행 후 직원이 처리 할 내용을 conflicts큐에 넣고 제공할 수 있다.</li>
</ul>
<h4 id="Saga-Pattern-microservice에서-어떻게-비즈니스-트랜잭션을-구현-할것인가"><a href="#Saga-Pattern-microservice에서-어떻게-비즈니스-트랜잭션을-구현-할것인가" class="headerlink" title="Saga Pattern : microservice에서 어떻게 비즈니스 트랜잭션을 구현 할것인가."></a>Saga Pattern : microservice에서 어떻게 비즈니스 트랜잭션을 구현 할것인가.</h4><p>트랜잭션은 어플리케이션의 필수적인 부분이다. 트랜잭션이 없다면 데이터의 일관성을 유지하는 것은 불가능하다.</p>
<p>가장 강력한 트랜잭션 유형중 하나는 Two-Phase Commit이다. 이는 여러 엔티티를 동시에 업데이트 할 때 유용하다.(ex. 주문확인 및 재고 업데이트)</p>
<p>그러나 microservice로 작업할 경우 데이터베이스가 분리되므로 로컬  Two-Phase Commit를 활용하여 전체 시스템의 일관성을 간단하게 유지할 수 없다. 이 경우 RDBMS와 마찬가지로 단일엔티티 원자 트랜잭션이 가능한 Couchbase와 같은 NoSQL 데이터베이스를 사용하면 수십배 빠르게 처리할 수 있다. 그래서 microservice를 사용하는 대다수 기업들이 NoSQL을 사용하고 있다.</p>
<h4 id="SAGA-Pattern"><a href="#SAGA-Pattern" class="headerlink" title="SAGA Pattern"></a>SAGA Pattern</h4><ul>
<li>분산 트랜잭션의 잘알려진 패턴중 하나가 SAGA이다.</li>
<li>SAGA는 일련의 local 트랙잭션들을 의미하며 각 트랜잭션은 하나의 서비스안에서 데이터를 업데이트 한다. 첫 번째 트랜잭션은 시스템 작업에 해당하는 외부 요청에 의해 시작되고 이후엔 이전단계 완료가 될 때마다 트리거링되어 작동한다.<br>-SAGA 트랜잭션을 구현하는 인기있는 두 가지 방법이 있다.<h4 id="1-Events-Choreography"><a href="#1-Events-Choreography" class="headerlink" title="1. Events/Choreography"></a>1. Events/Choreography</h4>각 서비스는 다른 서비스의 event, decides를 보고 action을 할지 말지 결정하며 non centralize 한것. (발레와 유사함)</li>
</ul>
<img src="/2019/06/08/msa3/EventsChoreography.PNG" alt="Events/Choreography" title="Events/Choreography">
<p>첫번째 서비스는 트랜잭션을 실행하고 이벤트를 publish한다. 발행된 이벤트는 하나 혹은 그 이상의 서비스가 지켜보며 해당 이벤트는 로컬 트랜잭션을 실행하고 새로운 이벤트를 publish한다.<br>분산 트랜잭션은 마지막에 서비스가 로컬 트랜잭션을 실행할 때 종료된되며 마지막 이벤트는 이벤트를 publish하지 않는다.<br>분산 트랜잭션의 경우 롤백에 대한 로직은 직접 만들어야 한다.</p>
<p>Event/Choreography design의 장단점</p>
<ul>
<li>이해하기 쉽고 SAGA패턴을 구현하는 자연스러운 방법이다. 구축에 많은 노력이 필요하지 않으며 느슨한 결합을 유지한다. 2~4단계로 구성되는 트랜잭션에 매우 적합하다.</li>
<li>어떤 서비스가 어떤 이벤트를 수신하는지 추적하기 어렵기 때문에 단계를 계속 추가할 경우 혼란스러울 수 있다.</li>
</ul>
<h4 id="2-Command-Orchestration-coordinator-서비스가-의사결정-및-sequncing-비즈니스-로직에-대한-책임이-있는-것-즉-centralize-한것-오케스트라와-유사함"><a href="#2-Command-Orchestration-coordinator-서비스가-의사결정-및-sequncing-비즈니스-로직에-대한-책임이-있는-것-즉-centralize-한것-오케스트라와-유사함" class="headerlink" title="2. Command/Orchestration : coordinator 서비스가 의사결정 및 sequncing 비즈니스 로직에 대한 책임이 있는 것. 즉 centralize 한것. (오케스트라와 유사함)"></a>2. Command/Orchestration : coordinator 서비스가 의사결정 및 sequncing 비즈니스 로직에 대한 책임이 있는 것. 즉 centralize 한것. (오케스트라와 유사함)</h4><img src="/2019/06/08/msa3/CommandOrchestration.PNG" alt="CommandOrchestration" title="CommandOrchestration">
<ul>
<li>Orchestration 접근법에서는 각 참가자에게 할 일을 알려줄 책임이 있는 새로운 서비스를 정의한다. 각 서비스와 명령/응답 형태로 통신하여 수행해야 할 작업을 알려준다.</li>
<li>위 그림의 경우 Orchestration은 트랜잭션을 실행하는데 필요한 흐름을 알고있다.</li>
<li>만약 트랜잭션이 실패하면 이전 작업을 취소하기 위해 각 참가자에게 롤백 명령을 보내야 한다. 롤백은 Orchestrator을 갖고있으면 훨씬 쉽다.</li>
<li>saga orchestrator을 모델링하는 표준 방법은 각 변환이 명령 또는 메세지에 해당하는지에 대한 State Machine이다. State Machine는 구현하기 쉽고 테스트에 적합하기 때문에 잘 정의된 동작을 구조화 하는데 훌륭한 패턴이다.</li>
</ul>
<p>Event/Choreography design의 장단점</p>
<ul>
<li>saga orchestrator는 saga participants를 호출할 수 있지만 saga participants는 saga orchestrator를 호출할수 없기에  서비스간 cyclic 종속성을 피할수 있다.</li>
<li>command에 대해 응답 혹은 실행만 하므로 participants간 복잡성을 줄일 수 있다.</li>
<li>새로운 단계가 추가될 때 트랜잭션의 복잡성은 linear하게 늘어난다.</li>
<li>쉬운 롤백관리 가능</li>
<li>첫번째,두번째 트랜잭션이 동일한 개체를 변경하고자 할 때 orchestrator를 활용하여 첫번째 트랜잭션이 끝날때 까지 두번째 트랜잭션을 보류상태로 둘 수 있다.</li>
<li>하지만 이는 orchestrator에 많은 로직이 들어가 risk가 있다</li>
<li>추가 서비스를 관리해야 하므로 인프라 복잡성이 증가한다.</li>
</ul>
<h4 id="Saga-Pattern-Tips"><a href="#Saga-Pattern-Tips" class="headerlink" title="Saga Pattern Tips"></a>Saga Pattern Tips</h4><p>트랜잭션마다 unique Id를 만들어라</p>
<ul>
<li>이를 통해 추적이 가능하고 participants간 통신을 위한 표준방법을 갖는데 도움을 준다.<br>command에 응답 address를 추가해라</li>
<li>participant가 고정된 주소에 응답하기 보다는 message에 응답 address를 추가하여 보내는것을 고려해봐라. 이를 통해 participants는 여러 orchestrator에 응답할 수 있다.</li>
<li>큐(SQS, Kafka, RabbitMQ, etc)를 사용할 경우 서비스간 통신할 수 있다.</li>
<li>버그로 인해 원치않은 메세지를 수신함으로써 데이터베이스가 엉망이 될 수 있다.<br>동기식 통신을 피하라</li>
<li>이를 통해 더 많은 데이터를 요청할 수 있고 다른 서비스가 오프라인 일 때도 서비스가 로컬 트랜잭션을 실행할 수 있다.</li>
<li>orchestrator는 각 요청/응답을 다뤄야하므로 선형적으로 복잡성이 증가한다.</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Database-Design-for-Microservices&quot;&gt;&lt;a href=&quot;#Database-Design-for-Microservices&quot; class=&quot;headerlink&quot; title=&quot;Database Design for Micros
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/tags/MSA/"/>
    
  </entry>
  
  <entry>
    <title>MSA이론2. Microservice Architecturure</title>
    <link href="http://KKimSangHeon.github.io/2019/06/08/msa2/"/>
    <id>http://KKimSangHeon.github.io/2019/06/08/msa2/</id>
    <published>2019-06-08T05:18:16.000Z</published>
    <updated>2019-06-09T08:21:58.499Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Microservices-Architecture"><a href="#Microservices-Architecture" class="headerlink" title="Microservices  Architecture"></a>Microservices  Architecture</h3><ul>
<li>비즈니스 로직을 나누었다.</li>
<li>큰 프로그램 대신 몇몇의 작은 어플리케이션이다.</li>
<li>잘 정의된 API로 소통한다.(HTTP, AMQP 활용)</li>
<li>하나의 서비스가 정지될경우 다른것에 영향을 미치지 않는다</li>
</ul>
<h4 id="What-is-Microservice-Architecture"><a href="#What-is-Microservice-Architecture" class="headerlink" title="What is Microservice Architecture?"></a>What is Microservice Architecture?</h4><ul>
<li>각각의 컴포넌트를 시스템에 집어넣는것이며 각각 빌드되고 배포될수 있다.</li>
<li>Microservice 는 vertical 하며 layered하다. 또한 Process driven 형태이다.</li>
<li>Microservice를 잘 정의하면 TDD가 가능하다.</li>
<li>엔터프라이즈 아키텍처가 아니다. Microservice Architecture는 SOA와 유사하다.</li>
<li>단일 비즈니스 기능을 구현한다.</li>
<li>자신만의 데이터베이스를 갖는것이 일반적이나 데이터베이스를 갖지않는경우도 있다.</li>
<li>HTTP, AMQP 로 통신한다.</li>
<li>독립적으로 배포가 가능하다.</li>
<li>각각의 레파지토리를 갖는다.</li>
<li>마이크로 서비스 팀은 몇명이 적당할까? 피자 두판을 먹을 수 있을만한 인원수! 6명 ? 좋다!</li>
</ul>
<h4 id="Microservice의-구성"><a href="#Microservice의-구성" class="headerlink" title="Microservice의 구성"></a>Microservice의 구성</h4><ul>
<li>Data Store</li>
<li>Application/Logic</li>
<li>Public API(POST, GET )</li>
</ul>
<h4 id="Microservices-application의-전형적인-생태계"><a href="#Microservices-application의-전형적인-생태계" class="headerlink" title="Microservices application의 전형적인 생태계"></a>Microservices application의 전형적인 생태계</h4><p>원칙1. Microservices들은 각 public API에 서로 의존한다.</p>
<ul>
<li>백엔드의 마이크로 서비스는 노출되면 안된다. 오직 프론트 마이크로 서비스만 노출되어야 한다.</li>
</ul>
<p>원칙2. 작업에 적합한 tool(ex. 프레임워크)을 사용하라.</p>
<p>원칙3. 서비스 보안에 신경써라</p>
<p>원칙4. 생태계에서 좋은 시민이 되어라!</p>
<ul>
<li>모니터링, 로깅, 추적을 분산하라</li>
</ul>
<p>원칙5. 기술 변화 이상의 것이다.</p>
<ul>
<li>조직 변화를 수용하라</li>
</ul>
<p>원칙6. 모든것을 자동화하라(DevOps!)</p>
<h4 id="Micro-Service를-위해서…"><a href="#Micro-Service를-위해서…" class="headerlink" title="Micro Service를 위해서…"></a>Micro Service를 위해서…</h4><ul>
<li>비즈니스 도메인을 이해하자</li>
<li>일관성 유지하자</li>
<li>서비스 발견해보자</li>
<li>불필요한 상호통신이 많다면 조정해보자</li>
</ul>
<h4 id="Microservice-계획하기"><a href="#Microservice-계획하기" class="headerlink" title="Microservice 계획하기"></a>Microservice 계획하기</h4><ul>
<li>정말 옳은 선택인가?(트레이드 오프 고려)</li>
<li>시스템의 주요기능을 식별하자</li>
<li>서비스 컴포넌트의 스코프를 세부적으로 결정하라(Function의 크기, 타입, 복잡성)</li>
<li>API들을 디자인하라</li>
<li>커뮤니케이션의 메커니즘을 결정하라</li>
<li>데이터 모델을 결정하라(중앙 데이터베이스 vs 여러 데이터 저장소)</li>
</ul>
<h4 id="Benefits-of-microservices"><a href="#Benefits-of-microservices" class="headerlink" title="Benefits of microservices"></a>Benefits of microservices</h4><ul>
<li>각각의 microservices를 쉽개 확장할 수 있다</li>
<li>빠른 빌드, 테스트, 릴리즈의 싸이클</li>
<li>agility의 증가</li>
<li>빠른혁신이 가능하다.</li>
<li>명확한 소유권 그리고 책임의 분배.</li>
</ul>
<h4 id="Microservice-Architecture"><a href="#Microservice-Architecture" class="headerlink" title="Microservice Architecture"></a>Microservice Architecture</h4>
<ul>
<li>각 microservice는 컨테이너에 할당된다. 컨테이너는 microservice 기반 어플리케이션을 개별적으로 개발, 배포하기 좋은 방법이다.</li>
<li>microservice 간 stateless server 형태로 소통한다.</li>
<li>클라이언트는 서비스를 바로 호출할수 없고 API 게이트웨이가 클라이언트의 요청을 적절한 microservice로 전달한다.<br>(API 게이트웨이는microservice로인가요? 하드웨어나 소프트웨어로 볼 수 있다. microservice로 일수도 있지만 아닐수도 있다.)</li>
<li>각 서비스는 상호 독립적이다.</li>
<li>Single-responsibility 원칙을 따름</li>
<li>아무것도 공유하지 않는다.</li>
<li>비동기가 가능하다.</li>
<li>configuration의 외부화</li>
<li>결합도가 느슨하다.</li>
<li>하나의 서비스가 문제를 일으켜도 나머지는 상관없다.</li>
</ul>
<h4 id="Microservices-Disadvantages"><a href="#Microservices-Disadvantages" class="headerlink" title="Microservices - Disadvantages"></a>Microservices - Disadvantages</h4><p>Complex networking으로 인해 데이터베이스, 서버의 오버헤드 발생</p>
<h4 id="Monolithic-Architecture-vs-Microservice-Architecture"><a href="#Monolithic-Architecture-vs-Microservice-Architecture" class="headerlink" title="Monolithic Architecture vs Microservice Architecture"></a>Monolithic Architecture vs Microservice Architecture</h4><img src="/2019/06/08/msa2/MonolithicArchitecturevsMicroservice.PNG" alt="Monolithic vs Microservice" title="Monolithic vs Microservice">
<p><code>Monolithic Architecture</code> : 모든 기능이 단일 코드베이스에 위치하고 하나의 DB를 사용한다. 또한 한 기능이 마비되면 전체가 마비되며 크고 복잡한 어플리케이션형태</p>
<h4 id="Microservices-vs-SOA"><a href="#Microservices-vs-SOA" class="headerlink" title="Microservices vs SOA"></a>Microservices vs SOA</h4><img src="/2019/06/08/msa2/MicroservicesvsSOA.PNG" alt="Microservices vs SOA" title="Microservices vs SOA">
<p>SOA 컨센은 centrallize이다.<br>MS는 not centrallize이다.<br>즉 SOA는 오케스트라와 같다. (한 지위자가 전체를 통솔한다) Microservices는 발레와 같다. (각 댄서가 각자 율동한다)</p>
<h4 id="Monolithic-Architecture-vs-SOA-vs-Microservices"><a href="#Monolithic-Architecture-vs-SOA-vs-Microservices" class="headerlink" title="Monolithic Architecture vs SOA vs Microservices"></a>Monolithic Architecture vs SOA vs Microservices</h4><img src="/2019/06/08/msa2/MonolithicArchitecturevsSOAvsMicroservices.PNG" alt="Microservices vs SOA" title="Microservices vs SOA">
<p><code>coarse-grained</code> : 특정 프로세스(서비스)를 큰 덩어리로 나누는것<br><code>fine-grained</code> :  특정 프로세스(서비스)를 잘게 쪼개는 것</p>
<h3 id="Microservices를-구현해야-하는-9가지-이유"><a href="#Microservices를-구현해야-하는-9가지-이유" class="headerlink" title="Microservices를 구현해야 하는 9가지 이유"></a>Microservices를 구현해야 하는 9가지 이유</h3><ul>
<li>Easy To Build &amp; Maintain</li>
<li>Continuous Delivery</li>
<li>Hybrid Technologies</li>
<li>Cross Team Coordination</li>
<li>Higher Quality Code</li>
<li>Smarter Scaling</li>
<li>Risk Reduction</li>
<li>Promote Big Data Best Practices</li>
<li>Improved ROI with reduced TCO</li>
</ul>
<h4 id="Illustration-of-Monolithic-Module-Refactoring"><a href="#Illustration-of-Monolithic-Module-Refactoring" class="headerlink" title="Illustration of Monolithic Module Refactoring"></a>Illustration of Monolithic Module Refactoring</h4><img src="/2019/06/08/msa2/IllustrationofMonolithicModuleRefactoring.PNG" alt="IllustrationofMonolithicModuleRefactoring" title="IllustrationofMonolithicModuleRefactoring">
<p>Microservice Architecture는 3계층이다.Container/ Orchestration /Application</p>
<h4 id="The-twelve-Factors"><a href="#The-twelve-Factors" class="headerlink" title="The twelve Factors"></a>The twelve Factors</h4><p>I. Codebase: One codebase that is tracked in revision control, with many deployments<br>II. Dependencies: Explicitly declare and isolate dependencies<br>III.Configuration: Store Configuration in the environment<br>IV.Backing services: Treat backing services as attached resources<br>V. Build, release, run: Strictly separate build and run stages<br>VI.Processes: Execute the app as one or more stateless processes<br>VII.Port binding: Export services with port binding<br>VIII.Concurrency: Scale out using the process model<br>IX.Disposability: 빠른 시작 및 효율적인 종료가 가능하다.<br>X. Development and production parity: Keep development, staging, and production as similar as possible<br>XI.Logs: Treat logs as event streams<br>XII.Admin processes: Run administrative and management tasks as one-off processes</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Microservices-Architecture&quot;&gt;&lt;a href=&quot;#Microservices-Architecture&quot; class=&quot;headerlink&quot; title=&quot;Microservices  Architecture&quot;&gt;&lt;/a&gt;Microse
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/tags/MSA/"/>
    
  </entry>
  
  <entry>
    <title>MSA이론1. Domain-Driven Design / Aggregates</title>
    <link href="http://KKimSangHeon.github.io/2019/06/06/msa1/"/>
    <id>http://KKimSangHeon.github.io/2019/06/06/msa1/</id>
    <published>2019-06-06T10:26:59.000Z</published>
    <updated>2019-06-09T08:21:59.817Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Implementing-Domain-Driven-Design-For-Microservices-Architecture"><a href="#Implementing-Domain-Driven-Design-For-Microservices-Architecture" class="headerlink" title="Implementing Domain-Driven Design For Microservices Architecture"></a>Implementing Domain-Driven Design For Microservices Architecture</h3><h4 id="DDD의-원칙"><a href="#DDD의-원칙" class="headerlink" title="DDD의 원칙"></a>DDD의 원칙</h4><p><code>Values:</code> Meaning, Unity, Usability, Fitness, Flexibility, Maintainability<br><code>Principles:</code>  Continuous Learning, Knowledge Rich Design, Ubiquitous Language, Model-Driven Design, Separation of Concerns<br>Deep Models, Declarative Style<br><code>Patterns:</code><br>Layered Architecture<br>Ubiquitous Language (Entities, Value Objects, Services, Modules, Aggregates, Factories, Specification) /<br>Supple Design (Intention-Revealing Interfaces, Side-Effect Free Functions, Assertions, Conceptual Contours, Standalone Classes, Closure of Operations)</p>
<h3 id="What-is-Domain-Driven-Design"><a href="#What-is-Domain-Driven-Design" class="headerlink" title="What is Domain Driven Design"></a>What is Domain Driven Design</h3><p>도메인 전문가, 기술 전문가가 소프트웨어 개발를 위해 협엽하는 기술<br>아이디어와 도메인은 공통언어를 통해 코드에 반영되어야 한다.<br>Domain Driven Design 에 대해 알아보기 위해 다양한 Domain에 대해 알아보자.</p>
<h4 id="Domain"><a href="#Domain" class="headerlink" title="Domain?"></a>Domain?</h4><p>팀은 특정 비즈니스 도메인에 맞게 일한다.<br>팀은 비즈니스 도메인에 초점을 맞춘다<br>도메인의 세부사항은 팀의 포지션마다 다르다.</p>
<p>도메인의 예시<br>Hotel / Banking / Mortgage / Credit / Debit Accounts / Credit Cards / Retails loans</p>
<h4 id="Subdomains"><a href="#Subdomains" class="headerlink" title="Subdomains"></a>Subdomains</h4><ul>
<li>도메인은 서브도메인으로 구성된다.</li>
<li>서브도메인은 Bounded Context와 유사하며 이는 서로 커뮤니케이션할 수 있다.</li>
<li>서브도메인은 또다른 서버도메인을 포함할 수 있다.</li>
</ul>
<h4 id="Core-domain"><a href="#Core-domain" class="headerlink" title="Core domain"></a>Core domain</h4><ul>
<li>돈을 벌게해주는 중요한 도메인</li>
<li>경쟁업체와 높은 차별성을 갖음</li>
</ul>
<h4 id="Supporting-Subdomain"><a href="#Supporting-Subdomain" class="headerlink" title="Supporting Subdomain"></a>Supporting Subdomain</h4><p>기술적으로 서포팅하지만 COTS-Software가 아니다.<br>외부지원으로 구현될수 있지만 사내 팀이 주도해야 한다.</p>
<p><code>Commercial, off-the-shelf</code><br>COTS 란 완성품으로 일반 대중에게 판매, 대여 또는 권한을 부여할 수 있는 컴퓨터 소프트웨어나 하드웨어, 기술 또는 컴퓨터 제품 등을 의미한다.</p>
<h4 id="Generic-Subdomain"><a href="#Generic-Subdomain" class="headerlink" title="Generic Subdomain"></a>Generic Subdomain</h4><p>Suitable for Outsourcing, COTS</p>
<h4 id="Bounded-Contexts"><a href="#Bounded-Contexts" class="headerlink" title="Bounded Contexts"></a>Bounded Contexts</h4><p>큰 도메인을 작은 Context로 나눈것.<br>각각의 Context는 자신만의 공통언어, 모델을 갖을 수 있다.<br>또한 Bounded Contexts는 일부 도메인을 공유할 수 있다.<br>Ubiquitous Language(공통언어)로 모델되어야 하며 프로그램에서 비즈니스 니즈를 정의한다.</p>
<h3 id="This-is-Domain-Driven-Design"><a href="#This-is-Domain-Driven-Design" class="headerlink" title="This is Domain Driven Design"></a>This is Domain Driven Design</h3><h4 id="DDD의-Concepts-and-Overview"><a href="#DDD의-Concepts-and-Overview" class="headerlink" title="DDD의 Concepts and Overview"></a>DDD의 Concepts and Overview</h4><p>Domain-Driven Desigin은 <u>기본 비즈니스 이해에 중점을 둔 소프트웨어 디자인방식이다.</u><br>이러한 접근방식은 다음 두가지 전제를 둔다.</p>
<ul>
<li>복잡한 도메인 디자인은 모델을 기반으로 한다.</li>
<li>대부분의 소프트웨어 프로젝트는 도메인 및 도메인로직에 중점을 둔다. (시스템 구현을 위한 특정 기술에 중점을 두는것이 아님)</li>
</ul>
<h4 id="전통적인-Layered-Architecture"><a href="#전통적인-Layered-Architecture" class="headerlink" title="전통적인 Layered Architecture"></a>전통적인 Layered Architecture</h4>
<p><code>User Interface</code>: 정보를 보여주고 사용자의 명령을 해석<br><code>Application</code> : 비즈니스 rule,지식 미포함 / 작업 조율 그리고 도메인에 작업 위임역할<br><code>Domain</code> : 비즈니스로직, 룰 포함/ 소프트웨어의 심장부<br><code>Infrastructure</code> : 상위 레이어를 지원하는 기술제공</p>
<h4 id="Domain-Driven-Design-with-Onion-Architecture"><a href="#Domain-Driven-Design-with-Onion-Architecture" class="headerlink" title="Domain-Driven Design with Onion Architecture"></a>Domain-Driven Design with Onion Architecture</h4>
<p><code>Core</code>: 특정 도메인이나 기술에 국한되지 않는 building blocks로 볼 수 있다. 예로 List, Maps, Case Classes, Actor and Lenses가 있다.<br><code>Domain</code> : 공통언어를 통해 작성된 비즈니스 로직 관련 메소드, 클래스가 상주하는 영역이다.<br><code>API</code> :  도메인의 진입점 역할을 한다. API는 도메인을 조작하지 못하도록 immutable한 객체만 노출해야 한다. 코어, 도메인은 API에 액세스할 수 있지만 Infrastructure는 API에 액세스할 수 없다.<br><code>Infrastructure</code> : DB, 사용자 인터페이스 같은 다얗안 기술을 포함하는 가장 바깥쪽 영역이다. 모든 영역은 Infrastructure 영역에 접근 할 수 있다.</p>
<h4 id="Bounded-Contexts-에-대해-자세히-알아보자"><a href="#Bounded-Contexts-에-대해-자세히-알아보자" class="headerlink" title="Bounded Contexts 에 대해 자세히 알아보자"></a>Bounded Contexts 에 대해 자세히 알아보자</h4><p>전체 비즈니스 모델은 너무 커 한번에 이해하기 힘들다. Bounded Contexts는 서로 다른 모델간 경계와 관계를 표현하기 위해 존재하는 명시적인 경계로서 경계 내의 Ubiquitous Language는 특정한 의미를 갖는다.</p>

<h4 id="Bounded-Context의-구현"><a href="#Bounded-Context의-구현" class="headerlink" title="Bounded Context의 구현"></a>Bounded Context의 구현</h4><ul>
<li>Bounded Context당 한팀이 존재한다.</li>
<li>코드 Repository가 Bounded Context마다 존재한다.</li>
<li>Domain Model + DB Schema + UI + Web Services (API)로 구성된다.</li>
</ul>
<p><u>Bounded Context는 Ubiquitous Language와 domain model을 캡슐화하나 도메인 모델과 상호작용하는 것, 도메인 모델을 서포트 하는 기능을 포함한다.  </u></p>
<p>또한 Bounded Context안에  Aggregates Entity(유니크한 트랜잭션), Value Object(불변의 객체)가 존재하는데 이는 바로 뒤에서 설명하니 참고하도록 하자.</p>
<h4 id="What-are-Entities"><a href="#What-are-Entities" class="headerlink" title="What are Entities?"></a>What are Entities?</h4><p><u>Domain object를 엔티티로 정의하는데 그것은 제각각 다르다</u>. 또한 엔티티의 정체성을 적절히 결정하고 어떻게 가져올지 결정한다.<br>최종 사용자,각 어플리케이션,data store은 <u>identity</u>를 만들어낸다.</p>
<h3 id="Aggregates"><a href="#Aggregates" class="headerlink" title="Aggregates"></a>Aggregates</h3><p>Aggregates는 루트엔티티로 간주되는 연관된 객체 그룹이다. (트랜잭션과 같음)</p>
<h4 id="Aggregates의-특징"><a href="#Aggregates의-특징" class="headerlink" title="Aggregates의 특징"></a>Aggregates의 특징</h4><ul>
<li>트랜잭션과 마찬가지로 Atomic, Consistent, Isolated, Durable 특징을 갖는다.<br>(사람모형 레고는 2개의 팔, 다리, 얼굴을 갖는데 이를 Product’s Invariant(불변성)이라 한다.)</li>
<li>경계가 명확하다.(외부 개체는 신경쓰지 않음)</li>
<li>내부 개체를 보호한다. 외부개체는 루트 Aggregates를 통해 접근 가능하며 Aggregates의 상태는 변경 불가능하다.</li>
<li>Aggregates는 자신이 소유한 entity, value object들의 무결성을 보호해야할 책임이 있다.</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">@Entity</div><div class="line">public class Cart implements Aggregate &#123;</div><div class="line">  @EmbeddedId</div><div class="line">  private CartId id;</div><div class="line">  @Embedded</div><div class="line">  private CustomerId customerId;</div><div class="line">  @OneToMany(cascade = CascadeType.All, orhanRemoval = true)</div><div class="line">  @JoinColumn(name=&quot;cartId&quot;)</div><div class="line">  private Set&lt;CartItem&gt; items;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>위와같은 코드가 있을 때 cart id는 루트 엔티티 이다. 또한 CartItem이라는 엔티티들의 레퍼런스를 갖고 있으며 CustomerId를 ValueObject로서 사용한다.</p>
<h4 id="Aggregates-rule"><a href="#Aggregates-rule" class="headerlink" title="Aggregates rule"></a>Aggregates rule</h4><ol>
<li>모델은 불변해야 하며 일관되게 경계안에 있어야 한다.</li>
<li>Aggregates 작게 디자인해라.(클 경우 확장성 저하 가능성)</li>
<li>다른 Aggregates참조는 Identity로 하라.</li>
<li>경계밖에서의 일관성유지</li>
</ol>
<h4 id="Relationships-Between-Aggregate"><a href="#Relationships-Between-Aggregate" class="headerlink" title="Relationships Between Aggregate"></a>Relationships Between Aggregate</h4><p>RelationshipsBetweenAggregate<br></p>
<p>Aggregate Root만 다른 Bounded Context의 Aggregate Root에 접근 가능</p>
<h4 id="Aggregate-팁"><a href="#Aggregate-팁" class="headerlink" title="Aggregate 팁"></a>Aggregate 팁</h4><ul>
<li>Aggregate는 항상 정답이 아니다.</li>
<li>Aggregates는 루트와 연결될 수 있다.</li>
<li>루트가 아닌 엔티티를 FK로 사용하는것을 간과하지 마라.</li>
</ul>
<h4 id="Aggregates가-중요한-이유"><a href="#Aggregates가-중요한-이유" class="headerlink" title="Aggregates가 중요한 이유"></a>Aggregates가 중요한 이유</h4><p>개체를 그룹화하고 카테고리화 하면 복잡한것을 쉽게 관리할 수 있다.<br>주인없는 레코드를 방지하여 GC가 쉬워진다.<br>DB와의 고수준의 통신이 가능케한다.</p>
<h3 id="Value-Object"><a href="#Value-Object" class="headerlink" title="Value Object"></a>Value Object</h3><p>가능한 엔티티 대신 값 개체를 사용하여 모델을 작성해야 한다.<br>Value 인지 아닌지 결정하기위해 다음 것들을 확인해보자.</p>
<ul>
<li>도메인을 측정하고, 정량화 할수있는지</li>
<li>불변의 상태로 유지될 수 할수있는지</li>
<li>관련된 속성을 필수 단위로 하여 전체를 구성하는지</li>
<li>상황이 바뀌면 교체 가능한지.</li>
<li>Value를 사용하는 다른값과 비교될 수 할수있는지</li>
<li>collaborators에게 부작용을 없는 행동을 하는지</li>
</ul>
<h3 id="What-are-Domain-Services"><a href="#What-are-Domain-Services" class="headerlink" title="What are Domain Services"></a>What are Domain Services</h3><p>도메인의 일부는 객체로 모델링하는것이 자연스럽지 않다.<br>Application Service와 다르다. Application Service는 Domain Service의 클라이언트다.<br>일반적인 사용 예</p>
<ul>
<li>성능이 중요한 비즈니스 프로세스</li>
<li>도메인 객체를 다른것의 구성요소로 변환할 때</li>
<li>둘 이상의 도메인 객체에서 입력을 요구할 때</li>
</ul>
<h3 id="Domain-Building-Blocks"><a href="#Domain-Building-Blocks" class="headerlink" title="Domain Building Blocks"></a>Domain Building Blocks</h3><p>Entity :</p>
<ul>
<li>identity가 있는 명사</li>
<li>가변적이며 다른 엔티티 혹은 value object와 연관될 수 있다.</li>
<li>공유될 수 없다.</li>
</ul>
<p>Value Object :</p>
<ul>
<li>identity가 없는 명사</li>
<li>불변하며 다른 엔티티와 연관될 수 있다..</li>
<li>공유될 수 있다.</li>
</ul>
<p>Aggregate :</p>
<ul>
<li>하나의 Aggregate당 하나의 root entity가 있다.</li>
<li>관련있는 Aggregate는 루트 entity를 통해 참조할 수 있지만 Aggregate의 다른 entity는 참조할 수 없다.</li>
<li>모든 작업은 루트를 통해 수행된다.</li>
</ul>
<p>Service :</p>
<ul>
<li>서비스는 어플리케이션에서의 액션이다.</li>
<li>서비스는 엔티티의 상태변화를 일으킨다</li>
<li>서비스는 상태가 없다.</li>
<li>서비스는 어플리케이션,도메인, 인프라스트럭쳐의 어느 곳의 일부가 될 수 있다.</li>
</ul>
<p>Factory :</p>
<ul>
<li>엔티티나 value object를 생성한다</li>
<li>엔티티의 생성이 복잡할 때 사용한다.</li>
</ul>
<h4 id="DDD의-이점"><a href="#DDD의-이점" class="headerlink" title="DDD의 이점"></a>DDD의 이점</h4><ul>
<li>기술보다는 비즈니스에 초점을 맞춘다,</li>
<li>코드르 재사용하고 읽기 쉽다.</li>
<li>개선사항이 있을 때 유연하다.</li>
</ul>
<h4 id="성공적인-DDD"><a href="#성공적인-DDD" class="headerlink" title="성공적인 DDD"></a>성공적인 DDD</h4><ul>
<li>도메인전문가, 기술 전문가의 협업을 통해 모델 빌드</li>
<li>어플리케이션의 반복적인 빌드</li>
<li>테스트하고 테스트하고 또 테스트하라</li>
</ul>
<h4 id="세계지도에서-DDD가-어떻게-적용되는지-보자"><a href="#세계지도에서-DDD가-어떻게-적용되는지-보자" class="headerlink" title="세계지도에서 DDD가 어떻게 적용되는지 보자."></a>세계지도에서 DDD가 어떻게 적용되는지 보자.</h4><p>Model Driven Desigin<br>Domain = Word Map<br>Sub domain = 오세아니아, 아시아, 북아메리카,….<br>Bounded Context = Countries(South Korea)<br>Ubiquitous Language = Korean Language<br>Domain Model = Map of Korea</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Implementing-Domain-Driven-Design-For-Microservices-Architecture&quot;&gt;&lt;a href=&quot;#Implementing-Domain-Driven-Design-For-Microservices-Arch
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/tags/MSA/"/>
    
  </entry>
  
  <entry>
    <title>13. 헬름</title>
    <link href="http://KKimSangHeon.github.io/2019/06/06/kube13/"/>
    <id>http://KKimSangHeon.github.io/2019/06/06/kube13/</id>
    <published>2019-06-06T08:17:59.000Z</published>
    <updated>2019-06-09T08:22:08.621Z</updated>
    
    <content type="html"><![CDATA[<p>하나 이상의 클러스터를 운영하다 보면 같은 어플리케이션을 여러 클러스터에 배포해야 하는 경우가 발생한다.<br>이럴 때 배포 환경에 따라 달라지는 설정값들때문에 문제점들이 많이 발생한다.</p>
<p>그래서 배포 환경에 따라 달라지는 설정값만 정의해 둔 다음 이에 따라 배포하는 메커니즘이 필요했는데 이를 해결한것이 바로 헬름이다.<br>헬름은 쿠버네티스 차트를 관리하기 위한 도구이다. 차트는 사전 구성된 쿠버네티스 리소스의 패키지다. 즉 헬름은 패키지 관리도구이며, 차트가 리소스를 하나로 묶은 패키지에 해당한다.</p>
<ol>
<li>헬름 : 차트를 관리</li>
<li>차트(매니패스트 템플릿으로 구성) : 차트를 사용하여 매니페스트 파일 생성</li>
<li>매니페스트 파일 : 매니페스트 파일에 기초한 쿠버네티스 리소스 관리</li>
<li>쿠버네티스</li>
</ol>
<p>헬름으로 차트를 관리하는 목적은 번잡해지기 쉬운 매니페스트 파일을 관리하기 쉽게하기 위한것이다. 헬름은 단순한 패키지 관리자가 아니라, 차트를 중심으로 하는 쿠버네티스 개발 업무의 종합 관리도구이다.</p>
<p>실무에서는 여러 환경에 배포해야 하는 어플리케이션은 모두 차트로 패키징해 kubectl 대신 헬름으로 배포 및 없데이트를 수행한다.</p>
<h3 id="헬름-설치"><a href="#헬름-설치" class="headerlink" title="헬름 설치"></a>헬름 설치</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ curl -LO https://git.io/get_helm.sh</div><div class="line">$ chmod 700 get_helm.sh</div><div class="line">$ ./get_helm.sh</div></pre></td></tr></table></figure>
<p>헬름 초기화<br>틸러라는 서버 어플리케이션이 kube-system 네임스페이스에 배포된다. 틸러는 helm 명령에따라 설치 등의 작업을 담당한다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ helm init</div></pre></td></tr></table></figure>
<p>잘 만들어졌나 확인해보자<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kubectl -n kube-system get service,deployment,pod --selector app=helm</div></pre></td></tr></table></figure></p>
<p>버전을 확인해보자.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ helm version</div></pre></td></tr></table></figure></p>
<p>여러 클러스터를 다룰 때는 클라이언트/서버의 버전을 일치시키는것이 좋다. 이를 위해 다음을 입력하여 업그레이드하자.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ helm init --upgrade</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;하나 이상의 클러스터를 운영하다 보면 같은 어플리케이션을 여러 클러스터에 배포해야 하는 경우가 발생한다.&lt;br&gt;이럴 때 배포 환경에 따라 달라지는 설정값들때문에 문제점들이 많이 발생한다.&lt;/p&gt;
&lt;p&gt;그래서 배포 환경에 따라 달라지는 설정값만 정
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>12. 사용자 관리와 RBAC(role-based access control)</title>
    <link href="http://KKimSangHeon.github.io/2019/06/06/kube12/"/>
    <id>http://KKimSangHeon.github.io/2019/06/06/kube12/</id>
    <published>2019-06-06T08:17:55.000Z</published>
    <updated>2019-06-09T07:34:17.107Z</updated>
    
    <content type="html"><![CDATA[<p>쿠버네티스 사용자마다 권한을 제어하는 것은 쿠버네티스 운영하는데 있어 보안을 확보하는 기본적인 방법이다.</p>
<p>쿠버네티스 사용자는 두 가지 개념으로 나뉜다.<br><code>일반사용자</code>: 클러스터 외부에서 쿠버네티스를 조작하는 사용자로 다양한 방법으로 인증을 거친다. 개발자 및 운영 실무자가 쿠버네티스를 조작하기 위해 사용하며 쿠버네티스 클러스터 외부로부터 들어오는 접근을 관리하기 위한 사용자이다.<br>배포와 관련된 서비스나 디플로이먼트의 접근 권한을 일부 사용자에게만 허용하거나 파드의 로그 열람 권한을 다른 일반 사용자에게도 허용하는 등의 정책을 일반 사용자 권한 부여로 실현할 수있다.</p>
<p><code>서비스 계정</code>: 쿠버네티스 내부적으로 관리되며 파드가 쿠버네티스 API를 다룰 때 사용하는 사용자.(kubectl또한 쿠버네티스 API와 통신해 작동함) 주어진 권한에 따라 쿠버네티스 리소스(파드, 디플로이먼트 등)를 다룰 수 있다.<br>서비스 계정은 어플리케이션을 통해 쿠버네티스 조작을 통제할 수 있다는 점이 장점이다. 클러스터 안에서 봇을 동작시키는 파드에 권한을 부여해두고, 이 봇으로 기존 디플로이먼트를 업데이트하거나 레플리카 수를 조절하는 식으로 활용할 수 있다.</p>
<p>서비스 계정 및 일반 사용자의 권한은 RBAC(role-based access control) 라는 메커니즘을 통해 제어된다. RBAC는 롤에 따라 리소스에 대한 권한을 제어하는 기능이자 개념이다.</p>
<p>Role, Cluster Role은 접근가능한것에 대한 범위이고 binding은 롤을 주는것을 의미한다고 판단.</p>
<p><code>롤</code> : 각 쿠버네티스 API의 사용권한을 정의. 네임스페이스 안에서만 유효<br><code>롤바인딩</code> : 일반 사용자 및 그룹/서비스 계정과 롤을 연결<br><code>클러스터롤</code>: 각 쿠버네티스 API의 사용 권한을 정의. 클러스터 전체에서 유효<br><code>클러스터롤바인딩</code>: 일반사용자 및 그룹/서비스 계정과 클러스터롤을 연결</p>
<p>262p부터</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;쿠버네티스 사용자마다 권한을 제어하는 것은 쿠버네티스 운영하는데 있어 보안을 확보하는 기본적인 방법이다.&lt;/p&gt;
&lt;p&gt;쿠버네티스 사용자는 두 가지 개념으로 나뉜다.&lt;br&gt;&lt;code&gt;일반사용자&lt;/code&gt;: 클러스터 외부에서 쿠버네티스를 조작하는 
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>11. 쿠버네티스 실전편(잡, 크론잡, 시크릿)</title>
    <link href="http://KKimSangHeon.github.io/2019/06/02/kube11/"/>
    <id>http://KKimSangHeon.github.io/2019/06/02/kube11/</id>
    <published>2019-06-02T08:11:52.000Z</published>
    <updated>2019-06-06T08:27:16.197Z</updated>
    
    <content type="html"><![CDATA[<p>파드, 레플리카세트, 디플로이먼트, 서비스, 인그레스는 데몬으로 동작하는 서버 어플리케이션을 구축할 때 사용되는 기본 리소스이다<br>쿠버네티스는 데몬으로 동작하는 서버 어플리케이션 외에도 배치 서버등 다양한 형태의 어플리케이션을 구축할 수 있다.</p>
<h3 id="잡"><a href="#잡" class="headerlink" title="잡"></a>잡</h3><p>잡은 하나 이상의 파드를 생성해 지정된 수의 파드가 정상 종료될 때까지 이를 관리하는 리소스다.<br>잡이 생성한 파드는 정상 종료된 후에도 삭제되지 않고 그대로 남아있기 때문에 작업이 종료된 후에 파드의 로그나 실행 결과를 분석할 수 있다. 그러므로 배치작업 위추의 어플리케이션에 적합하다.<br>잡은 파드 여러개를 병렬로 실행하는 방법으로 쉽게 스케일 아웃이 가능하다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">apiVersion: batch/v1</div><div class="line">kind: Job</div><div class="line">metadata:</div><div class="line">  name: pingpong</div><div class="line">  labels:</div><div class="line">    app: pingpong</div><div class="line">spec:</div><div class="line">  parallelism: 3    # 동시에 실행하는 파드의 수를 지정하는 속성. 파드를 병렬로 실행해야할 때 편리</div><div class="line">  template:</div><div class="line">    metadata:</div><div class="line">      labels:</div><div class="line">        app: pingpong</div><div class="line">    spec:</div><div class="line">      containers:</div><div class="line">      - name: pingpong</div><div class="line">        image: gihyodocker/alpine:bash</div><div class="line">        command: [&quot;/bin/sh&quot;]</div><div class="line">        args:</div><div class="line">          - &quot;-c&quot;</div><div class="line">          - |</div><div class="line">            echo [`date`] ping!</div><div class="line">            sleep 10</div><div class="line">            echo [`date`] pong!</div><div class="line">      restartPolicy: Never</div></pre></td></tr></table></figure>
<p>위의 코드를 yaml파일로 만들고 아래 명령어를 통해 확인해보자.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ kubectl apply -f test.yaml</div><div class="line">$ kubectl get pod -l app=pingpong --show-all</div></pre></td></tr></table></figure></p>
<p>parallelism와 replicas의 차이점은 무엇일까?<br>replicas가 3이면 동일한 파드를 3개 만들라는 것이고, parallelism이 이면 동시에 3개의 파드를 실행하는것인데… 확인해보니 parallelism도 파드를 3개 만들긴함.</p>
<p>잡 리소스는 restartPolicy 속성을 Never, OnFailure중 하나를 설정해야 한다.</p>
<h3 id="크론잡"><a href="#크론잡" class="headerlink" title="크론잡"></a>크론잡</h3><p>잡 리소스는 파드가 단 한번만 실행되는데 반해 크론잡 리소스는 스케줄을 지정해 정기적으로 파드를 실행할 수 있다. 즉 정기적으로 파드를 실행할 수 있다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">apiVersion: batch/v1beta1</div><div class="line">kind: CronJob</div><div class="line">metadata:</div><div class="line">  name: pingpong</div><div class="line">spec:</div><div class="line">  schedule: &quot;*/1 * * * *&quot;</div><div class="line">  jobTemplate:</div><div class="line">    spec:</div><div class="line">      template:</div><div class="line">        metadata:</div><div class="line">          labels:</div><div class="line">            app: pingpong</div><div class="line">        spec:</div><div class="line">          containers:</div><div class="line">          - name: pingpong</div><div class="line">            image: gihyodocker/alpine:bash</div><div class="line">            command: [&quot;/bin/sh&quot;]</div><div class="line">            args:</div><div class="line">              - &quot;-c&quot;</div><div class="line">              - |</div><div class="line">                echo [`date`] ping!</div><div class="line">                sleep 10</div><div class="line">                echo [`date`] pong!</div><div class="line">          restartPolicy: OnFailure</div></pre></td></tr></table></figure></p>
<p>spec.schedule속성에 Cron과 같은 포맷으로 파드를 실행할 스케줄을 정의한다. 또한 spec.jobTemplate 아래에 잡 리소스와 마찬가지로 파드 정의가 들어가면 된다.<br>보통의 경우 리눅스 crontab으로 스케줄에 맞춰 스크립트를 실행하는게 대부분이었따. 하지만 크론잡 리소스를 이용하면 이 모든것을 컨테이너로 해결할 수 있다.</p>
<h3 id="시크릿"><a href="#시크릿" class="headerlink" title="시크릿"></a>시크릿</h3><p>쿠버네티스의 시크릿 리소스를 사용하면 기밀정보 문자열을 Base 인코딩으로 만들 수 있다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">apiVersion: v1</div><div class="line">kind: Secret</div><div class="line">metadata:</div><div class="line">  name: nginx-secret</div><div class="line">type: Opaque</div><div class="line">data:</div><div class="line">  .htpasswd: eW91cl91c2VybmFtZTpyejc5SXpTalplaWZvCg==</div></pre></td></tr></table></figure>
<p>위 코드를 활용해 아래에 적용가능하다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line">apiVersion: v1</div><div class="line">kind: Service</div><div class="line">metadata:</div><div class="line">  name: basic-auth</div><div class="line">spec:</div><div class="line">  type: NodePort</div><div class="line">  selector:</div><div class="line">    app: basic-auth</div><div class="line">  ports:</div><div class="line">  - protocol: TCP</div><div class="line">    port: 80</div><div class="line">    targetPort: http</div><div class="line">    nodePort: 30060</div><div class="line"></div><div class="line">---</div><div class="line">apiVersion: apps/v1</div><div class="line">kind: Deployment</div><div class="line">metadata:</div><div class="line">  name: basic-auth</div><div class="line">  labels:</div><div class="line">    app: basic-auth</div><div class="line">spec:</div><div class="line">  replicas: 1</div><div class="line">  selector:</div><div class="line">    matchLabels:</div><div class="line">      app: basic-auth</div><div class="line">  template:</div><div class="line">    metadata:</div><div class="line">      labels:</div><div class="line">        app: basic-auth</div><div class="line">    spec:</div><div class="line">      containers:</div><div class="line">      - name: nginx</div><div class="line">        image: &quot;gihyodocker/nginx:latest&quot;</div><div class="line">        imagePullPolicy: Always</div><div class="line">        ports:</div><div class="line">          - name: http</div><div class="line">            containerPort: 80</div><div class="line">        env:</div><div class="line">          - name: BACKEND_HOST</div><div class="line">            value: &quot;localhost:8080&quot;</div><div class="line">          - name: BASIC_AUTH_FILE</div><div class="line">            value: &quot;/etc/nginx/secret/.htpasswd&quot;    </div><div class="line">        volumeMounts:</div><div class="line">          - mountPath: /etc/nginx/secret    # 이 경로에 .htpasswd가 생성된다.</div><div class="line">            name: nginx-secret</div><div class="line">            readOnly: true</div><div class="line">      - name: echo</div><div class="line">        image: &quot;gihyodocker/echo:latest&quot;</div><div class="line">        imagePullPolicy: Always</div><div class="line">        ports:</div><div class="line">          - containerPort: 8080</div><div class="line">        env:</div><div class="line">          - name: HTTP_PORT</div><div class="line">            value: &quot;8080&quot;</div><div class="line">      volumes:</div><div class="line">      - name: nginx-secret</div><div class="line">        secret:</div><div class="line">          secretName: nginx-secret</div></pre></td></tr></table></figure>
<p>인증정보를 환경 변수로 관리하는 기법또한 존재한다. 이는 259p를 참고하자.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;파드, 레플리카세트, 디플로이먼트, 서비스, 인그레스는 데몬으로 동작하는 서버 어플리케이션을 구축할 때 사용되는 기본 리소스이다&lt;br&gt;쿠버네티스는 데몬으로 동작하는 서버 어플리케이션 외에도 배치 서버등 다양한 형태의 어플리케이션을 구축할 수 있다
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>10. 쿠버네티스의 스토리지</title>
    <link href="http://KKimSangHeon.github.io/2019/06/01/kube10/"/>
    <id>http://KKimSangHeon.github.io/2019/06/01/kube10/</id>
    <published>2019-06-01T04:17:08.000Z</published>
    <updated>2019-06-02T08:11:02.042Z</updated>
    
    <content type="html"><![CDATA[<p>마스터 슬레이브 형태로 MySQL을 구성하자.</p>
<h3 id="쿠버네티스의-스토리지"><a href="#쿠버네티스의-스토리지" class="headerlink" title="쿠버네티스의 스토리지"></a>쿠버네티스의 스토리지</h3><p>쿠버네티스에서는 호스트에서 분리할 수 있는 외부 스토리지를 볼륨으로 사용할 수 있다. 파드가 다른 호스트로 재배치 되어도 외부 스토리지 형태의 볼륨은 새로 배치된 호스트에 자동으로 할당된다. 그러므로 호스트와 데이터 볼륨의 결합이 느슨해지고 외부 스토리지를 사용하므로 퍼시스턴스 데이터를 다루는 애플리케이션을 컨테이너로 운영하기가 쉽다.<br>쿠버네티스에서 관련 리소스는 다음의 요소들이 있다.</p>
<ul>
<li>퍼시스턴트볼륨</li>
<li>퍼시스턴트볼륨클레임</li>
<li>스토리지클래스</li>
<li>스테이트풀세트</li>
</ul>
<h3 id="퍼시스턴트볼륨과-퍼시트턴트볼륨클레임"><a href="#퍼시스턴트볼륨과-퍼시트턴트볼륨클레임" class="headerlink" title="퍼시스턴트볼륨과 퍼시트턴트볼륨클레임"></a>퍼시스턴트볼륨과 퍼시트턴트볼륨클레임</h3><p>퍼시스턴트볼륨은 스토리지 자체이며 퍼시스턴트볼륨클레임은 추상화된 논리 리소스로 퍼시스턴볼륨과 달리 용량을 필요한 만큼 동적으로 확보 할 수 있는것이다.<br>퍼시스턴트볼륨클레임은 클러스터가 구축된 플랫폼을 지원하는 퍼시스턴스 볼륨을 생성하기 위해 사용된다.</p>
<p>다음은 퍼시스턴스볼륨클레임 리소스의 매니페스트 파일이다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">apiVersion: v1</div><div class="line">kind: PersitentVolumeClaim</div><div class="line">metadata:</div><div class="line">  name: pvc-example</div><div class="line">spec:</div><div class="line">  accessModes:</div><div class="line">    - ReadWriteOnce</div><div class="line">  storageClassName: ssd</div><div class="line">  resource:</div><div class="line">    requests:</div><div class="line">      storage: 4Gi</div></pre></td></tr></table></figure></p>
<p>위의 <code>accessModes</code>는 파드가 스토리지에 접근한는 방식을 지정한다. ReadWriteOnce 는 마운트 될 수 있는 노드를 하나로 제한한다는 의미이다. 이 외에도 ReadOnlyMany 혹은 ReadWriteMany가 있다. 이들은 이러한 제약이 없으며 플랫폼에 따라 사용할 수 없는 경우가 있으므로 주의하<br><code>storageClassName</code>는 StorageClass리소스의 종류 즉 어떤 스토리지를 사용할지를 정의한다.</p>
<h3 id="스토리지클래스-StorageClass"><a href="#스토리지클래스-StorageClass" class="headerlink" title="스토리지클래스(StorageClass)"></a>스토리지클래스(StorageClass)</h3><p>스토리지클래스는 퍼시스턴트볼륨으로 확보한 스토리지 종류를 정의하는 리소스다. 앞에서의 storageClassName속성값의 실체가 이것이다. GCP의 경우 storageClassName의 종류는 표준,SSD가 있다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">kind: StorageClass</div><div class="line">apiVersion: storage.k8s.io/v1</div><div class="line">metadata:</div><div class="line">  name: ssd</div><div class="line">  annotations:</div><div class="line">    storageclass.kubernetes.io/is-default-class: &quot;false&quot;</div><div class="line">  labels:</div><div class="line">    kubernetes.io/cluster-service: &quot;true&quot;</div><div class="line">provisioner: kubernetes.io/gce-pd</div><div class="line">parameters:</div><div class="line">  type: pd-ssd</div></pre></td></tr></table></figure>
<p>SSD 스토리지를 사용하도록 스토리지 클래스의  name 속성을 ssd로 하고 provisioner는 GCP 의 퍼시스턴스 스토리지인 GCEPersistentDisk에 해당하는 gcd-pd로 지정한다. 그리고 파라미터의 type 속성값을 pd-ssd로 지정한다.</p>
<h3 id="스테이트풀세트-StatefulSet"><a href="#스테이트풀세트-StatefulSet" class="headerlink" title="스테이트풀세트(StatefulSet)"></a>스테이트풀세트(StatefulSet)</h3><p>디플로이먼트는 함께 포함된 파드 정의를 따라 파드를 생성하는 리소스로 하나만 있으면 되는 파드 혹은 퍼시스턴스 데이터를 갖지않는 즉 상태가 없는(stateless) 어플리케이션을 배포하는데 적합하다.<br><u>이에 비해 스테이트풀 세트는 데이터 스토어처럼 데이터를 계속 유지하는 상태가 있는 애플리케이션을 관리하는데 적합한 리소스다.</u></p>
<p>디플로이먼트에서 생성한 파드는 무작위로 생성된 식별자가 부여된다. <u>스테이트풀세트는 pod-1, pod-2, pod-2와 같이 일련번호가 붙는 유일한 식별자를 붙여 파드를 생성한다.</u><br>이 식별자는 파드를 재생성해도 유지되며, 스케일링 할 때도 식별자의 일련번호가 계속 이어진다.</p>
<p>파드가 재생성되어도 스토리지가 계속 같은 파드에 연결되어 파드의 데이터를 그대로 복원할 수 있다.</p>
<p>/</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;마스터 슬레이브 형태로 MySQL을 구성하자.&lt;/p&gt;
&lt;h3 id=&quot;쿠버네티스의-스토리지&quot;&gt;&lt;a href=&quot;#쿠버네티스의-스토리지&quot; class=&quot;headerlink&quot; title=&quot;쿠버네티스의 스토리지&quot;&gt;&lt;/a&gt;쿠버네티스의 스토리지&lt;/h3&gt;&lt;p&gt;쿠
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>9. GCP 를 활용한 실습환경 구축</title>
    <link href="http://KKimSangHeon.github.io/2019/06/01/kube9/"/>
    <id>http://KKimSangHeon.github.io/2019/06/01/kube9/</id>
    <published>2019-06-01T04:15:34.000Z</published>
    <updated>2019-06-09T08:23:09.708Z</updated>
    
    <content type="html"><![CDATA[<p>온프레미스 환경 또는 퍼블릭 클라우드에서 쿠버네티스를 실제로 사용해 보자.<br>클라우드에서 Google Kubernetes Engine을이용하거나 온프레미스 환경에서 Kuberspray를 이용해 클러스터를 구축하자</p>
<h3 id="윈도우-OS의-경우"><a href="#윈도우-OS의-경우" class="headerlink" title="윈도우 OS의 경우"></a>윈도우 OS의 경우</h3><p>GCP를 생성하고 구글 클라우드 SDK를 설치하자</p>
<p>아래의 링크에서 GCP 설치<br><a href="https://cloud.google.com/sdk/docs/quickstart-windows?hl=ko" target="_blank" rel="external">https://cloud.google.com/sdk/docs/quickstart-windows?hl=ko</a></p>
<p>환경변수에 다음 추가<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">C:\Users\SangHeon\AppData\Local\Google\Cloud SDK\google-cloud-sdk\bin</div></pre></td></tr></table></figure></p>
<p>gcloud 버전 업데이트<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ gcloud components update</div></pre></td></tr></table></figure></p>
<p>아래 입력 후 계정입력<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ gcloud auth login</div></pre></td></tr></table></figure></p>
<p>아래를 입력하여 대상 프로젝트 ID 선택<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ gcloud config set project xxxx</div></pre></td></tr></table></figure></p>
<p>아래 입력 하여 리전 설정<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ gcloud config set compute/zone asia-northeast1-a</div></pre></td></tr></table></figure></p>
<h3 id="CentOS일-때"><a href="#CentOS일-때" class="headerlink" title="CentOS일 때"></a>CentOS일 때</h3><p>Centos 환경에서의 진행</p>
<p>아래를 복붙하자<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">sudo tee -a /etc/yum.repos.d/google-cloud-sdk.repo &lt;&lt; EOM</div><div class="line">[google-cloud-sdk]</div><div class="line">name=Google Cloud SDK</div><div class="line">baseurl=https://packages.cloud.google.com/yum/repos/cloud-sdk-el7-x86_64</div><div class="line">enabled=1</div><div class="line">gpgcheck=1</div><div class="line">repo_gpgcheck=1</div><div class="line">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg</div><div class="line">       https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</div><div class="line">EOM</div></pre></td></tr></table></figure></p>
<p>아래 명령어 입력<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># sudo yum install google-cloud-sdk</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># gcloud init</div></pre></td></tr></table></figure>
<p>나오는 url로 들어가 코드 복사 및 붙여넣기</p>
<p>아래 입력 하여 리전 설정<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ gcloud config set compute/zone asia-northeast1-a</div></pre></td></tr></table></figure></p>
<h3 id="쿠버네티스-클러스터를-생성해보자"><a href="#쿠버네티스-클러스터를-생성해보자" class="headerlink" title="쿠버네티스 클러스터를 생성해보자"></a>쿠버네티스 클러스터를 생성해보자</h3><p> <a href="https://console.cloud.google.com/apis/api/container.googleapis.com/overview?project=xxxxxx" target="_blank" rel="external">https://console.cloud.google.com/apis/api/container.googleapis.com/overview?project=xxxxxx</a><br> 으로 접속해서 사용 설정가능토록 해주자</p>
<p>아래 명령어로 클러스터 생성<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ gcloud container clusters create sangheon --cluster-version=latest --machine-type=n1-standard-1 --num-nodes=3</div></pre></td></tr></table></figure></p>
<p>–cluster-version 으로 클러스터 버전 지정<br>–num-nodes  으로 인스턴수 수 지정</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ gcloud components install kubectl #센토스의 경우 안될경우 10줄짜리를 다시 복붙해보고 진행</div></pre></td></tr></table></figure>
<p>kubectl 에 인증정보 설정<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ gcloud container clusters get-credentials sangheon</div></pre></td></tr></table></figure></p>
<p>잘되었나 확인해보자<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kubectl get nodes</div></pre></td></tr></table></figure></p>
<p>다음을 입력하여 로컬에서 접속해보자<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubectl proxy</div></pre></td></tr></table></figure></p>
<hr>
<p>/</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;온프레미스 환경 또는 퍼블릭 클라우드에서 쿠버네티스를 실제로 사용해 보자.&lt;br&gt;클라우드에서 Google Kubernetes Engine을이용하거나 온프레미스 환경에서 Kuberspray를 이용해 클러스터를 구축하자&lt;/p&gt;
&lt;h3 id=&quot;윈도우-
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>8. 인그레스</title>
    <link href="http://KKimSangHeon.github.io/2019/05/29/kube8/"/>
    <id>http://KKimSangHeon.github.io/2019/05/29/kube8/</id>
    <published>2019-05-29T10:23:51.000Z</published>
    <updated>2019-05-29T12:56:24.086Z</updated>
    
    <content type="html"><![CDATA[<p>NodePort의 경우 L4레벨까지 다룰수 있기 때문에 HTTP/HTTPS처럼 경로를 기반으로 서비스를 전환하는 L7레벨의 제어는 불가능하다.<br>이를 해결하기 위한것이 인그레스이다. 서비스를 이용한 쿠버네티스 외부에 대한 노출(NodePort)과 가상 호스트 및 경로 기반의 정교한 HTTP 라우팅(인그레스)을 양립시킬 수 있다.<br>(무슨말인지 이해가 되지 않는다면 아래 밑줄부분을 보자.)</p>
<p>클러스터 외부에서 온 HTTP 요청을 서비스로 라우팅 하기위해 다음을 입력하자.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.16.2/deploy/mandatory.yaml</div><div class="line">$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.16.2/deploy/provider/cloud-generic.yaml</div><div class="line"></div><div class="line">$ kubectl get pod,svc -n ingress-nginx</div></pre></td></tr></table></figure></p>
<p>서비스를 다음과 같이 생성하고 반영시켜보자.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">apiVersion: v1</div><div class="line">kind: Service</div><div class="line">metadata:</div><div class="line">  name: echo</div><div class="line">spec:</div><div class="line">  selector:</div><div class="line">    app: echo</div><div class="line">  ports:</div><div class="line">    - name: http</div><div class="line">      port: 80</div></pre></td></tr></table></figure></p>
<p>다음과같이 인그레스를 정의하고 반영해보자.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">apiVersion: extensions/v1beta1</div><div class="line">kind: Ingress</div><div class="line">metadata:</div><div class="line">  name: echo</div><div class="line">spec:</div><div class="line">  rules:</div><div class="line">  - host: ch05.gihyo.local</div><div class="line">    http:</div><div class="line">      paths:</div><div class="line">      - path: /</div><div class="line">        backend:</div><div class="line">          serviceName: echo</div><div class="line">          servicePort: 80</div></pre></td></tr></table></figure></p>
<p>잘 생성되었는지 확인해보자.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kubectl get ingress</div></pre></td></tr></table></figure></p>
<p><u>인그레스는 L7 라우팅이 가능하므로 가상 호스팅 기능처럼 지정된 호스트 혹은 경로와 일치하는 서비스로 요청을 전달할 수 있다</u> 가령 헤더에 Mobile라는 값이 포함될경우 특정 URL로 리다이렉트 할 수 있다.</p>
<h3 id="apiVersion"><a href="#apiVersion" class="headerlink" title="apiVersion??"></a>apiVersion??</h3><p>항상 맨위에 위치하는 apiVersion은 무엇일까?<br>쿠버네티스 리소스를 생성, 수정, 삭제하는 작업은 쿠버네티스 클러스터에 배포된 API가 수행한다. 이 API는 여러 API를 하나로 묶은 형태로 구성되는데 이 apiVersion은 해당 작업에 사용되는 API의 종류를 나타내는 것이다. 다음명령어를 통해 쿠버네티스에서 사용할 수 있는 명령어들을 볼 수 있다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kubectl api-versions</div></pre></td></tr></table></figure></p>
<p>서비스나 파드는 쿠버네티스의 핵심 API인 v1, 디플로이먼트는 파드의 생성을 제어하는 API인 apps/v1에 해당한다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;NodePort의 경우 L4레벨까지 다룰수 있기 때문에 HTTP/HTTPS처럼 경로를 기반으로 서비스를 전환하는 L7레벨의 제어는 불가능하다.&lt;br&gt;이를 해결하기 위한것이 인그레스이다. 서비스를 이용한 쿠버네티스 외부에 대한 노출(NodePort
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>7. 서비스</title>
    <link href="http://KKimSangHeon.github.io/2019/05/29/kube7/"/>
    <id>http://KKimSangHeon.github.io/2019/05/29/kube7/</id>
    <published>2019-05-29T10:23:39.000Z</published>
    <updated>2019-05-29T10:24:38.043Z</updated>
    
    <content type="html"><![CDATA[<p>쿠버네티스 클러스터 안에서 파드의 집합(주로 레플리카세트)에 대한 경로나 서비스 디스커버리(API 주소가 동적으로 바뀌어도 클라이언트가 대상을 바꾸지않고 접근할 수 있음)를 제공하는 리소스이다. 서비스의 대상이 되는 파드는 서비스에서 정의하는 레이블 셀렉터로 정해진다. spec.selector 속성값으로 특정 파트의 레이블값을 설정하여 특정 파드만 접근할 수 있도록 yaml파일을 작성해보자.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">apiVersion: v1</div><div class="line">kind: Service</div><div class="line">metadata:</div><div class="line">  name: echo</div><div class="line">spec:</div><div class="line">  selector:     # 특정 파드만 접근할수 있도록 함.</div><div class="line">    app: echo</div><div class="line">    release: summer</div><div class="line">  ports:</div><div class="line">    - name: http</div><div class="line">      port: 80</div></pre></td></tr></table></figure>
<p>위의 서비스를 실행하고 컨테이너 안에 존재하는 아무 컨테이너에 들어가서 <code>curl http://echo</code> 를 입력하면 잘 동작하는것을 확인할 수 있다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ kubectl exec -it 파드명 bash</div><div class="line"></div><div class="line">혹은</div><div class="line"></div><div class="line">$ kubectl run -i --rm --tty debug --image=gihyodocker/fundamental:0.1.0 --restart=Never -- bash -il</div><div class="line"></div><div class="line"></div><div class="line"># curl http://echo</div></pre></td></tr></table></figure></p>
<p>다음명령어를 통해 로그를 summer안에서 생기는 로그를 확인할 수 있다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kubeclt logs -f echo-summer-dtblk -c echo</div></pre></td></tr></table></figure></p>
<p>쿠버네티스 클러스터는 <code>서비스명.네임스페이스명.svc.local</code>로 연결해준다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ curl http://echo.default.svc.local</div><div class="line"></div><div class="line">$ curl http://echo.default</div><div class="line"># svc.local 생략가능</div><div class="line"></div><div class="line">$ curl http://echo  </div><div class="line"># 같은네임스페이스일 경우만 가능</div></pre></td></tr></table></figure>
<h3 id="ClusterIP-서비스"><a href="#ClusterIP-서비스" class="headerlink" title="ClusterIP 서비스"></a>ClusterIP 서비스</h3><p>서비스의 종류는 여러가지가 있고 기본값은 ClusterIP 서비스이다. ClusterIP를 통해 클러스터 내부 IP 주소에 서비스를 공개할 수 있다.</p>
<h3 id="NodePort-서비스"><a href="#NodePort-서비스" class="headerlink" title="NodePort 서비스"></a>NodePort 서비스</h3><p>이는 클러스터 외부에서 접근할 수 있는 서비스이다. ClusterIP를 만든다는 점은 ClusterIP 서비스와 같다. 각 노드에서 서비스 포트로 접속하기 위한 글로벌 포트를 개방하는것이 차이점이다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">apiVersion: v1</div><div class="line">kind: Service</div><div class="line">metadata:</div><div class="line">  name: echo</div><div class="line">spec:</div><div class="line">  type: NodePort  # 추가함</div><div class="line">  selector:     </div><div class="line">    app: echo</div><div class="line">    release: summer</div><div class="line">  ports:</div><div class="line">    - name: http</div><div class="line">      port: 80</div></pre></td></tr></table></figure>
<p>다음 명령어를 통해 포트를 알아내고 curl요청을 보낼 수 있다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kubectl get svc echo</div></pre></td></tr></table></figure></p>
<h3 id="LoadBalancer-서비스"><a href="#LoadBalancer-서비스" class="headerlink" title="LoadBalancer 서비스"></a>LoadBalancer 서비스</h3><p>이는 각 클라우드 플랫폼에서 제공하는 로드밸런서와 연동하기 위해 사용된다.</p>
<h3 id="ExternalName-서비스"><a href="#ExternalName-서비스" class="headerlink" title="ExternalName 서비스"></a>ExternalName 서비스</h3><p>이는 셀렉터도 포트 정의도 없는 특이한 서비스다. 쿠버네티스 클러스터에서 외부 호스트를 네임 레졸루션 하기위한 별칭을 제공한다.<br>아래의 경우 gihyo.jp를 gihyo로 참조할 수 있게해준다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">apiVersion: v1</div><div class="line">kind: Service</div><div class="line">metadata:</div><div class="line">  name: gihyo</div><div class="line">spec:</div><div class="line">  type: ExternalName  # 추가함</div><div class="line">  externalName: gihyo.jp</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;쿠버네티스 클러스터 안에서 파드의 집합(주로 레플리카세트)에 대한 경로나 서비스 디스커버리(API 주소가 동적으로 바뀌어도 클라이언트가 대상을 바꾸지않고 접근할 수 있음)를 제공하는 리소스이다. 서비스의 대상이 되는 파드는 서비스에서 정의하는 레
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>6.쿠버네티스의 주요 개념(리소스 개요,파드,네임스페이스,레플리카세트,디플로이먼트</title>
    <link href="http://KKimSangHeon.github.io/2019/05/27/kube6/"/>
    <id>http://KKimSangHeon.github.io/2019/05/27/kube6/</id>
    <published>2019-05-27T11:01:24.000Z</published>
    <updated>2019-05-29T10:21:11.518Z</updated>
    
    <content type="html"><![CDATA[<p><code>docker container prune</code><br>docker container prune [options]<br>도커를 오래 사용하다 보면 디스케이 컨테이너와 이미지가 점점 늘어나게 된다. 이런 경우 prune 명령을 사용해 필요없는 컨테이너를 일괄 삭제할 수 있다.</p>
<p>docker image prune [options]<br>도커를 오래 사용하다 보면 디스케이 컨테이너와 이미지가 점점 늘어나게 된다. 이런 경우 prune 명령을 사용해 필요없는 이미지를 일괄 삭제할 수 있다.</p>
<p>docker system prune [options]<br>사용하지 않는 도커 이미지 및 컨테이너,볼륨,네트워크 등 모든 리소스를 일괄적으로 삭제할 수 있다.</p>
<p>쿠버네티스로 실행하는 애펄리케이션은 애플리케이션을 구성하는 다양한 리소스가 함께 연동해 동작한다.</p>
<h3 id="리소스의-종류-및-용도"><a href="#리소스의-종류-및-용도" class="headerlink" title="리소스의 종류 및 용도"></a>리소스의 종류 및 용도</h3><p><code>노드</code> : 컨테이너가 배치되는 서버<br><code>네임스페이스</code> : 쿠버네티스 클러스터 안의 가상 클러스터.<br><code>파드</code> : 컨테이너의 집합 중 가장 작은 단위로 컨테이너 실행 방법을 정의한다.<br><code>레플리카 세트</code>: 같은 스펙을 갖는 파드를 여러개 생성하고 관리하는 역할을 한다.<br><code>디플로이먼트</code> : 레플리카 세트의 리비전을 관리한다.<br><code>서비스</code>: 파드의 집합에 접근하기 위한 경로를 정의한다.<br><code>인그레스</code>:서비스를 쿠버네티스 클러스터 외부로 노출시킨다.<br><code>컨피그맵</code> : 설정 정보를 정의하고 파드에 전달한다.<br><code>퍼시스턴트 볼륨</code> : 파드가 사용할 스토리지의 크기 및 종류를 정의.<br><code>퍼시스턴스 볼륨 클레임</code> : 퍼시스턴트 볼륨을 동적으로 확보.<br><code>스토리지 클래스</code> : 퍼시스턴트 볼륨이 확보하는 스토리지의 종류를 정의<br><code>스테이트풀 세트</code> : 같은 스펙으로 모두 동일한 파드를 여러개 생성하고 관리한다.<br><code>잡</code>: 상주 실행을 목적으로 하지 않는 파드를 여러개 생성하고 정상적인 종료를 보장한다.<br><code>크론잡</code>: 크론 문법으로 스케줄링되는 잡.<br><code>시크릿</code> : 인증 정보같은 기밀 데이터를 정의한다.<br><code>롤</code>: 네임스페이스 안에서 조작 가능한 쿠버네티스 리소스의 규칙을 정의한다.<br><code>롤바인딩</code>: 쿠버네티스 리소스 사용자와 롤을 연결 짓는다.<br><code>클러스터룰</code>: 클러스터 전체적으로 조작 가능한 쿠버네티스 리소스의 규칙을 정의한다.<br><code>클러스터롤바인딩</code>:쿠버네티스 리소스 사용자와 클러스터 롤을 연결 짓는다.<br><code>서비스 계정</code>: 파드가 쿠버네티스 리소스를 조작할 때 사용하는 계정</p>
<h3 id="쿠버네티스-클러스터와-노드"><a href="#쿠버네티스-클러스터와-노드" class="headerlink" title="쿠버네티스 클러스터와 노드"></a>쿠버네티스 클러스터와 노드</h3><p>쿠버네티스 리소스 중에서 가장 큰 개념은 노드이다. 쿠버네티스는 클러스터 전체를 관리하는 서버인 마스터가 적어도 하나 이상 있어야 하며 쿠버네티스 클러스터는 마스터와 노드의 그룹으로 구성된다.</p>
<h3 id="네임스페이스"><a href="#네임스페이스" class="headerlink" title="네임스페이스"></a>네임스페이스</h3><p>쿠버네티스는 클러스터 안에 가상 클러스터를 또 다시 만들 수 있다. 이를 네임스페이스라 한다. 클러스터를 처음 구축하면 default, docker, kube-public, kube-system의 네임스페이스 4개가 이미 만들어져 있다.</p>
<h3 id="파드"><a href="#파드" class="headerlink" title="파드"></a>파드</h3><p>파드는 컨테이너가 모인 집합체의 단위로 적어도 하나 이상의 컨테이너로 이루어진다. 쿠버네티스에서는 결합이 강한 컨테이너를 파드로 묶어 일괄 배포한다.<br>파드 하나는 여러 노드에 걸쳐 배치될 수 없다. 함께 배포해야 정합성을 유지할 수 있는 컨테이너 등에도 해당 컨테이너를 같은 파드로 묶어두는 전략이 유용하다.<br>쿠버네티스에서는 관리용 서버인 마스터가 클러스터 전체를 제어하며 마스터 노드는 관리용 컴포넌트가 담긴 파드만 배포된 노드이다. 어플리케이션에 사용되는 파드는 배포할 수 없다.</p>
<h3 id="파드생성-및-배포"><a href="#파드생성-및-배포" class="headerlink" title="파드생성 및 배포"></a>파드생성 및 배포</h3><p>파드생성은 kubectl만 사용해도 가능하지만, 버전관리 관점에서도 yaml파일로 정의하는것이 좋다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">apiVersion: v1  # 리소스의 유형을 지정하는 속성</div><div class="line">kind: Pod</div><div class="line">metadata:       # 리소스에 부여되는 메타데이터. metadata.name 속성의 값이 리소스의 이름이 된다.</div><div class="line">  name: simple-echo</div><div class="line">spec:           # 리소스를 정의하기 위한 속성.</div><div class="line">  containers:</div><div class="line">  - name: nginx # 컨테이너 이름</div><div class="line">    image: gihyodocker/nginx:latest # 도커 허브에 저장된 이미지 태그값</div><div class="line">    env:        # 환경변수</div><div class="line">    - name: BACKEND_HOST</div><div class="line">      value: localhost:8080</div><div class="line">    ports:      # 컨테이너가 노출시킬 포트를 지정 (도커파일에서 지정한 경우 따로 지정할필요 x)</div><div class="line">    - containerPort: 80</div><div class="line">  - name: echo</div><div class="line">    image: gihyodocker/echo:latest</div><div class="line">    ports:</div><div class="line">    - containerPort: 8080</div></pre></td></tr></table></figure>
<p>아래 명령어를 입력하여 클러스터에 배포할 수 있다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ kubectl apply -f simple-pod.yaml</div><div class="line">$ kubectl get pod</div><div class="line">를 입력하여 파드 정보를 볼 수 있다. READY에 분모는 파드에 정의된 컨테이너 수이고 분자는 실행 상태의 컨테이너 수 이다.</div></pre></td></tr></table></figure></p>
<p>아래 명령어를 통해 파드안에 있는 컨테이너의 표준 출력을 화면에 출력할 수 있다.<br>뒤 -c는 컨테이너를 지정한것.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kubectl logs -f simple-echo -c echo</div></pre></td></tr></table></figure></p>
<p>파드를 삭제하기 위해 다음명령어를 사용할 수 있다<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kubectl delete pod simple-echo</div></pre></td></tr></table></figure></p>
<p>매니페스트 파일로도 파드를 삭제할 수 있다. 이 경우 메니패스트에 작성된 리소스 전체가 삭제된다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kubectl delete -f simple-pod.yaml</div></pre></td></tr></table></figure>
<p>파드에는 각각 고유의 가상 IP주소가 할당된다. 이는 파드에 속하는 모든 컨테이너가 공유하며 이로인해 같은 파드 안의 모든 컨테이너의 가상 IP가 같기 때문에 컨테이너간 통신이 가능해진다.</p>
<h3 id="레플리카세트"><a href="#레플리카세트" class="headerlink" title="레플리카세트"></a>레플리카세트</h3><p>레플리카세트는 똑같은 정의를 갖는 파드를 여러개 생성하고 관리하기 위한 리소스다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">apiVersion: apps/v1</div><div class="line">kind: ReplicaSet</div><div class="line">metadata:</div><div class="line">  name: echo</div><div class="line">  labels:</div><div class="line">    app: echo</div><div class="line">spec:</div><div class="line">  replicas: 3</div><div class="line">  selector:</div><div class="line">    matchLabels:</div><div class="line">      app: echo</div><div class="line">  template: # template 아래는 파드 리소스 정의와 같음</div><div class="line">    metadata:</div><div class="line">      labels:</div><div class="line">        app: echo</div><div class="line">    spec:</div><div class="line">      containers:</div><div class="line">      - name: nginx</div><div class="line">        image: gihyodocker/nginx:latest</div><div class="line">        env:</div><div class="line">        - name: BACKEND_HOST</div><div class="line">          value: localhost:8080</div><div class="line">        ports:</div><div class="line">        - containerPort: 80</div><div class="line">      - name: echo</div><div class="line">        image: gihyodocker/echo:latest</div><div class="line">        ports:</div><div class="line">        - containerPort: 8080</div></pre></td></tr></table></figure>
<h3 id="디플로이먼트"><a href="#디플로이먼트" class="headerlink" title="디플로이먼트"></a>디플로이먼트</h3><p>레플리카세트보다 상위에 해당하는 리소스로 디플로이먼트가 있다. 디플로이먼트는 어플리케이션 배포의 기본단위가 되는 리소스이다.<br>디플로이먼트의 정의는 레플리카세트의 정의와 크게 다르지 않다. 차이가 있다면 디플로이먼트가 레플리카세트의 리비전 관리를 할 수 있다는 점 정도다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">apiVersion: apps/v1</div><div class="line">kind: Deployment</div><div class="line">metadata:</div><div class="line">  name: echo</div><div class="line">  labels:</div><div class="line">    app: echo</div><div class="line">spec:</div><div class="line">  replicas: 3</div><div class="line">  selector:</div><div class="line">    matchLabels:</div><div class="line">      app: echo</div><div class="line">  template: # template 아래는 파드 리소스 정의와 같음</div><div class="line">    metadata:</div><div class="line">      labels:</div><div class="line">        app: echo</div><div class="line">    spec:</div><div class="line">      containers:</div><div class="line">      - name: nginx</div><div class="line">        image: gihyodocker/nginx:latest</div><div class="line">        env:</div><div class="line">        - name: BACKEND_HOST</div><div class="line">          value: localhost:8080</div><div class="line">        ports:</div><div class="line">        - containerPort: 80</div><div class="line">      - name: echo</div><div class="line">        image: gihyodocker/echo:patched</div><div class="line">        env:</div><div class="line">        - name: HOGE</div><div class="line">          value: fuga</div><div class="line">        ports:</div><div class="line">        - containerPort: 8080</div></pre></td></tr></table></figure>
<h3 id="레플리카세트의-생애주기"><a href="#레플리카세트의-생애주기" class="headerlink" title="레플리카세트의 생애주기"></a>레플리카세트의 생애주기</h3><p>실제운영에서는 디폴로이먼트 매니페스트 파일을 통해 레플리카 세트를 다룬다.<br>디플로이먼트를 수정하면 레플리카세트가 새로 생성되고 기존 레플리카 세트와 교체된다.</p>
<h4 id="레플리카-세트의-다양한-경우의-수"><a href="#레플리카-세트의-다양한-경우의-수" class="headerlink" title="레플리카 세트의 다양한 경우의 수"></a>레플리카 세트의 다양한 경우의 수</h4><p>파드 개수만 수정할 경우 (replicas값을 3에서 4로) 레플리카세트가 새로 생성되지 않는다.</p>
<p>컨테이너 이미지가 수정된 경우 기존 파드는 단계적으로 정지된다. 또한 <code>kubectl rollout history deployment echo</code>를 입력해보면 새로운 리비전으로 변경된것을 확인할 수 있다.</p>
<h3 id="롤백하기"><a href="#롤백하기" class="headerlink" title="롤백하기"></a>롤백하기</h3><p>undo를 실행하면 디플로이먼트가 바로 직전 리비전으로 롤백된다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kubectl rollout undo deployment echo</div></pre></td></tr></table></figure></p>
<p>디플로이먼트는 다음 명령어를 통해 삭제할 수 있다. 이와 관련된 레플리카세트와 파드가 함께 삭제된다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kubectl delete -f simple-deployment.yaml</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;docker container prune&lt;/code&gt;&lt;br&gt;docker container prune [options]&lt;br&gt;도커를 오래 사용하다 보면 디스케이 컨테이너와 이미지가 점점 늘어나게 된다. 이런 경우 prune 명령을 사용해
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>5.도커 운영과 관리를 위한 명령</title>
    <link href="http://KKimSangHeon.github.io/2019/05/26/kube5/"/>
    <id>http://KKimSangHeon.github.io/2019/05/26/kube5/</id>
    <published>2019-05-26T08:30:05.000Z</published>
    <updated>2019-05-27T12:19:49.742Z</updated>
    
    <content type="html"><![CDATA[<p><code>docker container prune</code><br>docker container prune [options]<br>도커를 오래 사용하다 보면 디스케이 컨테이너와 이미지가 점점 늘어나게 된다. 이런 경우 prune 명령을 사용해 필요없는 컨테이너를 일괄 삭제할 수 있다.</p>
<p>docker image prune [options]<br>도커를 오래 사용하다 보면 디스케이 컨테이너와 이미지가 점점 늘어나게 된다. 이런 경우 prune 명령을 사용해 필요없는 이미지를 일괄 삭제할 수 있다.</p>
<p>docker system prune [options]<br>사용하지 않는 도커 이미지 및 컨테이너,볼륨,네트워크 등 모든 리소스를 일괄적으로 삭제할 수 있다.</p>
<p><code>docker iamge prune</code><br>docker image prune [options]<br>이미지도 컨테이너와 마찬가지로 사용하지 않는 것이 점차 누적된다. 디스크 용량을 너무 차지하지 않도록 정기적으로 삭제 해줘야 한다. docker image prune명령은 태그가 붙지않은 모든 이미지를 삭제한다.</p>
<p><code>docker system prune</code><br>사용하지 않는 도커 이미지 및 컨테이너, 볼륨, 네트워크 등 모든 도커 리소스를 일괄적으로 삭제한다.</p>
<p><code>docker container stats</code><br>시스템 리소스 사용 현황을 컨테이너 단위로 확인할 때 사용한다. 유닉스 계열 운영 체제의 top 명령과 같은 역할을 한다고 보면 된다.<br>docker container stats [options] [대상_컨테이너ID]</p>
<p>80P부터</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;docker container prune&lt;/code&gt;&lt;br&gt;docker container prune [options]&lt;br&gt;도커를 오래 사용하다 보면 디스케이 컨테이너와 이미지가 점점 늘어나게 된다. 이런 경우 prune 명령을 사용해
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>4.도커 컨테이너 다루기</title>
    <link href="http://KKimSangHeon.github.io/2019/05/26/kube4/"/>
    <id>http://KKimSangHeon.github.io/2019/05/26/kube4/</id>
    <published>2019-05-26T08:29:48.000Z</published>
    <updated>2019-05-26T08:32:04.209Z</updated>
    
    <content type="html"><![CDATA[<p>컨테이너는 파일 시스템과 어플리케이션이 함께 담겨있는 박스이다.</p>
<h3 id="컨테이너의-생명주기"><a href="#컨테이너의-생명주기" class="headerlink" title="컨테이너의 생명주기"></a>컨테이너의 생명주기</h3><p>도커 컨테이너는 실행 중, 정지, 파기의 3가지 상태를 갖는다. 이를 도커 컨테이너의 생애주기라고 한다. 각 컨테이너는 같은 이미지로 생성했더라도 다른 상태를 갖는다.</p>
<p><code>실행 중 상태</code> : docker container run 명령의 인자로 지정된 도커 이미지를 기반으로 컨테이너가 생성되면 이 이미지를 생성했던 Dockerfile에 포함된 CMD 및 ENTRYPOINT 인스트럭션에 정의된 어플리케이션이 실행된다. 이를 실행 중 상태라고 한다.<br>서버의 경우 실행 기간이 길지만 명령이 바로 실행되고 끝나는 명령행 도구 등의 컨테이너는 실행 중 상태가 길게 유지되지 않는다.</p>
<p><code>정지 상태</code><br>실행 중 상태에 있는 컨테이너를 사용자가 명시적으로 정지하거나 컨테이너에서 실행된 어플리케이션이 정상/오류 여부를 막론하고 자동으로 정지 상태가 된다.<br>정지시키면 가상 환경으로는 더 이상 동작하지 않지만, 종료되던 시점의 상태가 저장돼 남는다. 그러므로 정지시킨 컨테이너를 다시 실행할 수 있다.</p>
<p><code>파기상태</code><br>정 상태의 컨테이너는 명시적으로 파기하지 않는 이상 디스크에 그대로 남아있다. 한번 파기한 컨테이너는 다시는 실행할 수 없다.</p>
<p><code>docker container run</code><br>도커 이미지로부터 컨테이너를 생성하고 실행하는 명령이다. 도커 컨테이너를 싱행중 상태로 만들기 위해 사용한다.<br>docker container run [options] 이미지명[:태그] [명령] [명령인자..]<br>docker container run [options] 이미지ID [명령] [명령인자..]</p>
<p>docker container run -it alpine:3.7 uname -a<br>이 경우 Dockerfile에 정의되어있는 CMD 인스트럭션을 오버라이딩하여 uname -a가 실행되도록 할 수 있다.</p>
<p>컨테이너 이름 붙이기<br>컨테이너를 다루는 명령을 실행할 때는 ID등으로 컨테이너를 특정해줘야 한다. 매번 docker container ls를 통해 id나 이름을 확인하기 번거롭기 때문에 이름을 붙여 활용할 수 있다.<br>docker container run –name [컨테이너명] [이미지명]:[태그]</p>
<p><code>docker container ls</code><br><code>docker container ls [options]</code><br>실행 중이거나 종료된 컨테이너의 목록을 보여주는 명령</p>
<p>docker container ls -q 를 통해 컨테이너 ID만 추출할 수 있다.</p>
<p><code>docker container stop</code><br>docker container stop 컨테이너ID<em>또는</em>컨테이너명<br>실행중인 컨테이너를 정지하는 명령이다.</p>
<p><code>docker container restart</code><br>docker container restart 컨테이너ID<em>또는</em>컨테이너명<br>파기하지 않은 정지 상태의 컨테이너 재시작</p>
<p><code>docker container rm</code><br>docker container rm 컨테이너ID<em>또는</em>컨테이너명</p>
<p><code>docker container logs</code><br>현재 실행중인 특정 도커 컨테이너의 표준 출력 내용을 확인할 수 있다.<br>docker container logs [options] 컨테이너ID<em>또는</em>컨테이너명</p>
<p><code>docker container exec</code><br>docker container exec [options] 컨테이너ID<em>또는</em>컨테이너명 컨테이너에서<em>실행할</em>명령</p>
<p><code>docker container cp</code><br>컨테이너끼리 혹은 컨테이너와 호스트간에 파일을 복사하기 위한 명령이다. Dockerfile에 포함된 COPY 인스트럭션은 이미지를 빌드할 때 호스트에서 복사해 올 파일을 정의하기 위한것이고, docker container cp 명령은 실행중인 컨테이너와 파일을 주고받기 위한 명령이다.</p>
<p>컨테이너 안에 있는 /echo/main.go 파일을 호스트의 현재 작업 디렉터리로 복사하려면 다음과 같이 하면된다.<br>docker container cp echo:/echo/main.go .</p>
<p>호스트쪽에서 컨테이너로 파일을 복사하려면 다음과 같이 한다.<br>docker container cp dummy.txt echo:/tmp</p>
<p>/</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;컨테이너는 파일 시스템과 어플리케이션이 함께 담겨있는 박스이다.&lt;/p&gt;
&lt;h3 id=&quot;컨테이너의-생명주기&quot;&gt;&lt;a href=&quot;#컨테이너의-생명주기&quot; class=&quot;headerlink&quot; title=&quot;컨테이너의 생명주기&quot;&gt;&lt;/a&gt;컨테이너의 생명주기&lt;/h
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>3. 도커 이미지 다루기</title>
    <link href="http://KKimSangHeon.github.io/2019/05/22/kube3/"/>
    <id>http://KKimSangHeon.github.io/2019/05/22/kube3/</id>
    <published>2019-05-22T11:48:50.000Z</published>
    <updated>2019-05-26T08:31:11.662Z</updated>
    
    <content type="html"><![CDATA[<p>도커이미지는 도커 컨테이너를 만들기 위한 템플릿이다<br>컨테이너의 템플릿 역할을 하는 이미지를 만드는 과정을 일반적으로 도커 이미지를 빌드한다고 한다. 그리고 컨테이너를 실행할 때 빌드된 이미지를 사용한다.</p>
<p><code>docker image build</code><br>도커파일에 기술된 구성을 따라 도커 이미지를 생성하는 명령.<br>docker image build -t 이미지명[:태그명] Dockerfile의 경로</p>
<p><code>docker search</code><br>docker search [options] 검색_키워드<br>도커 허브에 등록된 레파지토리를 검색할 수 있다.<br>docker search jenkins 를 하면<br>docker search library/jenkins와 같다.<br>공식 레파지토리의 네임스페이스는 일률적으로 library이다.</p>
<p><code>docker image pull</code><br>docker image pull [options] 리포지토리명[:태그명]<br>인자로 지정한 레포지토리명과 태그는 도커 허브에 이미 존재하야 한다.</p>
<p><code>docker image ls</code><br>호스트 운영체제에 저장된 도커 이미지의 목록을 보여준다.</p>
<p><code>docker image tag</code><br>도커 이미지의 특정 버전에 태그를 붙일 때 사용한다.<br>태그는 이미지의 특정 버전을 구별하기 위한것이다.<br>같은 태그에 여러 도커이미지를 빌드했을 때 최근 빌드된 이미지만 해당 태그를 갖고 나머지는 none가 된다.<br>태그는 이미지 ID에 태그명을 별명으로 붙이는 명령이다.<br>도커 이미지는 빌드할 때마다 다시 생성되는데 그 내용의 해시값을 이미지 ID로 삼기 때문에 내용이 바뀌면 이미지 ID도 새값으로 바뀐다.<br>docker image tag 기반이미지명[:태그] 새이미지명[:태그]</p>
<p><code>docker image push</code><br>도커 이미지를 도커 허브 등의 레지스트리에 등록하기 위해 사용<br>docker image push [options] 리포지토리명[:태그]</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;도커이미지는 도커 컨테이너를 만들기 위한 템플릿이다&lt;br&gt;컨테이너의 템플릿 역할을 하는 이미지를 만드는 과정을 일반적으로 도커 이미지를 빌드한다고 한다. 그리고 컨테이너를 실행할 때 빌드된 이미지를 사용한다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker 
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>2.도커 컨테이너 실행</title>
    <link href="http://KKimSangHeon.github.io/2019/05/21/kube2/"/>
    <id>http://KKimSangHeon.github.io/2019/05/21/kube2/</id>
    <published>2019-05-21T10:16:49.000Z</published>
    <updated>2019-05-23T13:06:39.516Z</updated>
    
    <content type="html"><![CDATA[<p>도커에서 제공하는 스크립트로 설치</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo wget -qO- https://get.docker.com/ | sh</div><div class="line">$ sudo usermod -aG docker shkim</div></pre></td></tr></table></figure>
<p><code>도커 이미지</code> : 도커 컨테이너를 구성하는 파일 시스템과 실행할 어플리케이션 설정을 하나로 합친것으로, 컨테이너를 생성하는 템플릿 역할을 한다.</p>
<p><code>도커 컨테이너</code> : 도커 이미지를 기반으로 생성되며, 파일 시스템과 어플리케이션이 구체화돼 실행되는 상태.</p>
<p>Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?<br>이라는 에러 뜰 때</p>
<p>sudo systemctl start docker</p>
<p>실습<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo docker image pull gihyodocker/echo:latest</div></pre></td></tr></table></figure></p>
<p>위를 입력하여 이미지를 내려받자.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker container run -t -p 9000:8080 gihyodocker/echo:latest</div></pre></td></tr></table></figure>
<p>를 입력하여 내부 8080포트로 포트포워딩이 가능토록 해보자</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ curl http://localhost:9000</div></pre></td></tr></table></figure>
<p>을 입력하면 정상적으로 동작함을 볼 수 있다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker container stop $(docker container ls -q)</div></pre></td></tr></table></figure>
<p>을 입력하여 컨테이너를 중지시킬 수 있다.</p>
<h3 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><p><code>FROM</code> : 도커 이미지의 바탕이 될 베이스 이미지. dOCKERFILE로 이미지를 빌드할 때 먼저 from 인스트럭션에 지정된 이미지를 내려받는다. 받아오는 이미지는 모두 도커 허브 레지스트리에 공개된 것이다. 콜론 뒤에 붙는것은 버전이라고 볼 수 있다.</p>
<p><code>RUN</code> : 도커 이미지를 실행할 때 컨테이너 안에서 실행할 명령을 정의하는 인스트럭션. 도커 안에서 실행할 명령을 그대로 기술한다.</p>
<p><code>COPY</code> : 도커가 동작중인 호스트 머신의 파일이나 디렉토리를 도커 컨테이너 안으로 복사하는 인스트럭션이다.</p>
<p><code>CMD</code> : 도커 컨테이너를 실행할 때 컨테이너 안에서 실행할 프로세스를 지정한다. RUN은 이미지를 빌드할 때 실행되고 CMD는 컨테이너를 시작할 때 한번 실행된다. RUN은 어플리케이션 업데이트 및 배치에, CMD는 어플리케이션 자체를 실행하는 명령이라고 생각하면된다.<br>CMD [“실행파일”,”인자1”,”인자2”] - 실행파일에 인자를 전달한다.<br>CMD 명령 인자1, 인자2 - 명령과 인자를 지정한다. 셸에서 실행되므로 셸에 정의된 변수를 참조할 수 있다.<br>CMD [“인자1”, “인자2”] - ENTRYPOINT에 지정된 명령에 사용할 인자를 전달한다.</p>
<p><code>ENTRYPOINT</code> : 컨테이너의 명령 실행 방식을 조정할 수 있다. CMD와 마찬가지로 컨테이너안에서 실행할 프로세스를 지정하는 인스트럭션인다. ENTRYPOINT를 지정하면 CMD의 인자가 ENTRYPOINT에서 실행하는 파일에 인자로 주어진다. 즉, ENTRYPOINT에 지정된 값이 기본 프로세스를 지정하는 것이다.</p>
<p><code>LAVEL</code> : 이미지를 만든 사람의 이름 등을 적을 수 있다.</p>
<p><code>ENV</code> : 도커 컨테이너 안에서 사용할 수 있는 환경변수를 지정한다.</p>
<p><code>ARG</code> : 이미지를 빌드할 때 정보를 함께 넣기위해 사용한다. 이미지를 빌드할 때만 사용할 수 있는 임시적인 환경변수 이다.<br>``</p>
<h3 id="도커-이미지-빌드"><a href="#도커-이미지-빌드" class="headerlink" title="도커 이미지 빌드"></a>도커 이미지 빌드</h3><p>도커파일 작성이 끝났으면 docker image build 명령으로 도커 이미지를 빌드할 수 있다.</p>
<p>문법은 다음과 같다.<br>-t 옵션으로 이미지명을 지정한다. 태그명도 지정할 수 있으며 생략시에는 latest태그가 붙는다.<br><u>-t 옵션과 이미지명은 반드시 지정해야 한다고 생각하는 편이 좋다. -t 옵션 없이도 빌드 자체는 가능하지만, 이미지명 없이는 해시값만으로 이미지를 구분해야 하므로 사용하기 번거롭다.</u></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker image build -t 이미지명[:태그명] Dockerfile의 경로</div></pre></td></tr></table></figure>
<p>실습을 진행해보자<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker image build -t example/echo:lastest .</div></pre></td></tr></table></figure></p>
<p>example은 네임스페이스를 의미한다. 이미지명에 이렇게 사용자 네임스페이스를 추가할 수 있으며 이미지명의 충돌을 피하기 위해 네임스페이스를 붙이는것이 좋다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker image ls</div></pre></td></tr></table></figure>
<p>를 입력하여 생성된 이미지의 정보를 확인할 수 있다.</p>
<h3 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">FROM golang:1.10</div><div class="line"></div><div class="line">ENTRYPOINT [&quot;go&quot;]</div><div class="line">CMD [&quot;&quot;]</div></pre></td></tr></table></figure>
<p>위와같이 도커파일을 만들고 아래를 입력하여 빌드해보자</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker image build -t sh/golang:latest .</div></pre></td></tr></table></figure>
<p>아래 명령어는 컨테이너 안에 들어가 <code>go version</code>을 입력한 것과 같다.<br>즉 아래 명령어의 version이 도커파일의 CMD 부분에 대입되는것이다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker container run sh/golang:latest version</div></pre></td></tr></table></figure></p>
<p>이처럼 ENTRYPOINT는 이미지를 생성하는 사람이 컨테이너의 용도를 어느정도 제한하려는 경우에도 유용하다.</p>
<h3 id="도커-컨테이너-실행"><a href="#도커-컨테이너-실행" class="headerlink" title="도커 컨테이너 실행"></a>도커 컨테이너 실행</h3><p>다음 명령어로 실행 할 수 있다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker container run example/echo:latest</div></pre></td></tr></table></figure></p>
<p>다음 명령어로 데몬으로 실행할 수 있다. 명령어의 결과로 나오는 값은 컨테이너의 id이다. 도커 명령으로 컨테이너를 조작할 때 사용된다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker container run -d example/echo:latest</div></pre></td></tr></table></figure></p>
<h3 id="포트-포트포워딩"><a href="#포트-포트포워딩" class="headerlink" title="포트 포트포워딩"></a>포트 포트포워딩</h3><p>HTTP 요청을 받는 애플리케이션은 컨테이너 밖에서 온 요청을 컨테이너 안에 있는 어플리케이션에 전달해줘야 한다. 이를 바로 포트 포워딩이라 한다. 포트 포워딩이란 호스트 머신의 포트를 컨테이너 포트와 연결해 컨테이너 밖에서 온 통신을 컨테이너 포트로 전달한다. 이 기능 덕분에 컨테이너 포트를 컨테이너 외부에서도 이용할 수 있다.</p>
<p>다음 명령어로 포트포워딩을 할 수 있다. 9000포트로 접속할 경우 컨테이너 내부 8080포트로 연결된다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker container run -d -p 9000:8080 example/echo:latest</div></pre></td></tr></table></figure></p>
<p>또는 아래와 같이 빈 포트로 자동할당되도록 할 수 있다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">$ docker container run -d -p 8080 example/echo:latest</div><div class="line">// 빈 포트가 에페메랄 포트로 자동 할당된다.</div><div class="line">$ docker container ls</div><div class="line">//포트를 확인해보자</div></pre></td></tr></table></figure></p>
<p>/</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;도커에서 제공하는 스크립트로 설치&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/d
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>1.도커의 기초</title>
    <link href="http://KKimSangHeon.github.io/2019/05/18/kube1/"/>
    <id>http://KKimSangHeon.github.io/2019/05/18/kube1/</id>
    <published>2019-05-18T14:49:26.000Z</published>
    <updated>2019-05-20T13:39:41.371Z</updated>
    
    <content type="html"><![CDATA[<h3 id="도커-amp-쿠버네티스"><a href="#도커-amp-쿠버네티스" class="headerlink" title="도커 &amp; 쿠버네티스"></a>도커 &amp; 쿠버네티스</h3><p>도커와 쿠버네티스에 대해 더 공부해보고 싶어 아래책을 구매하였고 포스팅해 볼 예정이다.<br><img src="/2019/05/18/kube1/dockerandkube.jpg" alt="[도커/쿠버네티스를 활용한 컨테이너 개발 실전 입문]" title="[도커/쿠버네티스를 활용한 컨테이너 개발 실전 입문]"></p>
<h3 id="도커란-무엇인가"><a href="#도커란-무엇인가" class="headerlink" title="도커란 무엇인가"></a>도커란 무엇인가</h3><p>도커는 컨테이너형 가상화 기술을 구현하기 위한 상주 어플리케이션(dockered라는 데몬)과 이 어플리케이션을 조작하기 위한 명령행 도구로 구성되는 프로덕트이다. 어플리케이션 배포에 특화되어 있기 때문에 어플리케이션 개발 및 운영을 컨테이너 중심으로 할 수 있다.<br>로컬 환경에 도커만 설치하면 몇 줄짜리 구성 파일과 명령어 한줄로 어플리케이션이나 미들웨어가 이미 갖춰진 테스트용 가상환경을 빠르게 구축할 수 있다. 가상화 소프트웨어와 비교해도 오버헤드가 적이진다는 장점이 있다.</p>
<p>도커의 장점</p>
<ul>
<li>기존 가상화 소프트웨어보다 더 가볍다.</li>
<li>이식성이 뛰어나다.</li>
<li>설치가 번거로운 명령형 도구를 도커 컨테이너로 가져다 사용함으로써 호스트를 깔금하게 유지하면서도 바로 실행할 수 있다.</li>
<li>다양한 의존 라이브러리나 도구를 도커 컨테이너에 포함시켜 배포함으로써 실행 환경과 상관없이 스크립트의 동작 재현성을 높임.</li>
<li>도커 컨테이너를 HTTP  부하 테스트의 워커로 사용해  HTTP 요청 수를 증가시킴.</li>
</ul>
<p>컨테이너는 운영체제의 동작을 완전히 재현하지는 못하기 때문에 엄밀한 리눅스 계열 운영체제의 동작이 요구되는 가상환경을 구축해야 한다면 VMWare가 더 적합할 수 있다.</p>
<h3 id="컨테이너-가상화"><a href="#컨테이너-가상화" class="headerlink" title="컨테이너 가상화?"></a>컨테이너 가상화?</h3><p>도커는 컨테이너형 가상화 기술을 사용하는데 이를통해 가상화 소프트웨어 없이도 운여 체제의 리소스를 격리해 가상 운영체제로 만들 수 있다. 이 가상 운영 체제를 컨테이너라 한다.  컨테이너를 만들면서 발생하는 오버헤드는 다른 가상화 소프트웨어보다 더 적다. 빠르게 시작 및 종료할 수 있고 이에 들어가는 리소스도 작은 편이다.</p>
<h3 id="운영체제-가상화"><a href="#운영체제-가상화" class="headerlink" title="운영체제 가상화?"></a>운영체제 가상화?</h3><p>운영체제 위에서 가상화 소프트웨어를 사용해 하드웨어를 에뮬레이션 하는 방법으로 게스트 운영체제를 만드는 방식을 호스트 운영체제 가상화 라고 한다. 컨테이너형 가상화와 비교하면 구조적으로 오버헤드가 크다.</p>
<img src="/2019/05/18/kube1/image1.png" alt="운영체제 가상화 / 컨테이너 가상화" title="운영체제 가상화 / 컨테이너 가상화">
<p>컨테이너 가상화의 경우 하이퍼바이저와, Guest OS를 만들지 않는것을 확인할 수 있다.</p>
<p>그림에 대해 조금 더 알아보자</p>
<p>VMware, VirtualBox는 호스트 OS위에 게스트 OS 전체를 가상화 하여 사용하는 방식 도커는 게스트 OS를 설치하는 방식이 아닌 서버 운영을 위한 라이브러리만 이미지에 담아 설치하게 되므로 기존의 방법들(전가상화, 반가상화)보다 경량화 된 상태입니다. 즉, 하드웨어를 가상화하는 계층이 없어졌기 때문에 기존 가상머신에 대해 보다 빠른 속도를 제공합니다.<br><code>https://real-dongsoo7.tistory.com/60 참고</code></p>
<p>컨테이너는 하이퍼바이저와 다르다. 컨테이너는 하이퍼바이저와 가상화라는 같은 목표를 갖고 있다. 하지만 하이퍼바이저는 OS 및 커널이 통째로 가상화 되지만 컨테이너는 파일시스템만 가상화가 된다. 컨테이너는 호스트 PC의 커널을 공유한다. 따라서 init등의 프로세스가 떠 있을 필요가 없고 가상화 프록르ㅐㅁ과는 다르게 적은 메모리 사용량 적은 오버헤드를 보인다.</p>
<h3 id="도커를-사용하는-의의"><a href="#도커를-사용하는-의의" class="headerlink" title="도커를 사용하는 의의"></a>도커를 사용하는 의의</h3><p>변화하지 않는 실행환경으로 멱등성 확보<br>코드를 통한 실행환경 구축 및 어플리케이션 구성<br>실행환경과 어플리케이션의 일체화로 이식성 향상<br>시스템을 구성하는 어플리케이션 및 미들웨어의 관리 용이성</p>
<p>환경의 차이로 인해 발생하는 문제에 대해 나온것들<br>1.코드로 관리하는 인프라<br>코드 기반으로 인프라를 정의한다는 개념. 멱등성을 확보하기위해 어플리케이션이 의존하는 런타임이나 라이브러리 모두가 확실하게 특정 버전으로 설치되도록 해야한다. <u>멱등성 보장을 위해 항구적인 코드를 계속적으로 작성하는것은 운영 업무에 부담을 주기 쉽다. 또한 서버의 대수가 늘어날 수록 모든서버에 구성을 적용하는 시간도 늘어난다. 이러한 문제에 대한 대책이 불변인프라 개념이다.</u></p>
<p>2.불변인프라<br><u>불변 인프라는 어떤 시점의 서버 상태를 저장해 복제할 수 있게 하자는 개념이다. </u>제대로 설정된 상태의 서버를 항상 사용할 수 있단는 점이 가장 큰 장점이다. 서버에 변경을 가하고 싶은 경우에는 기존 인프라를 수정하는 대신 새로운 서버를 구축하고 그 상태를 이미지로 저장한 다음 그 이미지를 복제한다. 한번 설정된 서버는 수정없이 파기되므로 멱등성을 신경쓸 필요가 없다.</p>
<p>도커를 활용할 경우 위의 두 개념을 쉽고 낮은 비용으로 실현할 수 있다. 도커는 컨테이너형 가상화 기술을 사용하다. 가상 머신의 OS를 재현하는게아닌 운영체제 대부분을 호스트 운영체제와 공유한다. 실행에 걸리는 시간이 짧은만큼 인프라를 완전히 새로 만드는 불변 인프라와 궁합이 잘 맞는다.</p>
<p>도커 컴포즈가 단일 서버를 넘어 여러 서버에 걸쳐있는 여러 컨테이너를 관리할 수 있도록 한 도구가 도커 스웜이다. 여러컨테이너를 관리하는 것만이 목적인 도커 컴포즈와 달리 도커 스웜은 컨테이너 증가 혹은 감소는 물론이고 노드의 리소스를 효율적으로 활용하기 위한 컨테이너 배치 및 로드 밸런싱 기능 등 더욱 실용적인 기능을 갖추고 있다. 또한 롤링업데이트(오래된 컨테이너와 새로운 컨테이너를 단계적으로 서비스에 교체 투입하는것)가 가능하다. 이처럼 여러 서버에 걸쳐있는 여러 컨테이너를 관리하는 기법을 <code>컨테이너 오케스트레이션</code>이라 한다.</p>
<p>컨테이너 오케스트레이션 분야에서 사실상 표준으로 자리 잡은 것은 <code>쿠버네티스</code>이다.</p>
<p>도커를 통해 인프라와 어플리케이션이 모두 컨테이너 형태로 제공되면서 인프라와 어플리케이션의 설정을 모두 코드수준에서 쉽게 수정할 수 있게됐다. 기존에는 명확했던 인프라 엔지니어와 서버 사이드 엔지니어의 영역 구분이 점점 희미해지고 있다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;도커-amp-쿠버네티스&quot;&gt;&lt;a href=&quot;#도커-amp-쿠버네티스&quot; class=&quot;headerlink&quot; title=&quot;도커 &amp;amp; 쿠버네티스&quot;&gt;&lt;/a&gt;도커 &amp;amp; 쿠버네티스&lt;/h3&gt;&lt;p&gt;도커와 쿠버네티스에 대해 더 공부해보고 싶어 아
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>(K8s) 6. 윈도우에서 실습해보기</title>
    <link href="http://KKimSangHeon.github.io/2019/05/06/kubernetes6/"/>
    <id>http://KKimSangHeon.github.io/2019/05/06/kubernetes6/</id>
    <published>2019-05-06T14:26:48.000Z</published>
    <updated>2019-05-06T14:28:07.985Z</updated>
    
    <content type="html"><![CDATA[<p>도커툴박스설치</p>
<p><a href="https://docs.docker.com/toolbox/overview/" target="_blank" rel="external">https://docs.docker.com/toolbox/overview/</a></p>
<p>virtual machine 가 없다면 체크하여 설치</p>
<p>PowerShell 관리자 권한으로 실행</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div><div class="line">$ ExecutionPolicy      &lt;-- 현재상태확인</div><div class="line">$ Set-ExecutionPolicy Unrestricted</div><div class="line"></div><div class="line"></div><div class="line">$ Set-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString(&apos;https://chocolatey.org/install.ps1&apos;))</div><div class="line"></div><div class="line">$ choco install minikube kubernetes-cli</div><div class="line"></div><div class="line">$ kubectl run sangheonkim --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080</div><div class="line"></div><div class="line"></div><div class="line">$ minikube dashboard</div></pre></td></tr></table></figure>
<p>파드 내부에서 출력하는 로그를 보자<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ kubectl get pods</div><div class="line">를 통해 파드의 정보를 복사하자,</div><div class="line">$ kubectl logs $POD_NAME</div></pre></td></tr></table></figure></p>
<p>컨테이너로 들어가서 여러 명령어를 실행해보자<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ kubectl exec $POD_NAME env</div><div class="line"></div><div class="line">$ kubectl exec -ti $POD_NAME bash</div></pre></td></tr></table></figure></p>
<p>서비스를 만들어보자</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ kubectl get services</div><div class="line">서비스를 확인해보자. 미니쿠베가 만든게 하나 존재한다.</div><div class="line"></div><div class="line">$ kubectl expose deployment/sangheonkim --type=&quot;NodePort&quot; --port 8080</div><div class="line">서비스를 노출시켜보자</div><div class="line"></div><div class="line">$ kubectl describe services/sangheonkim</div><div class="line">서비스를 자세히 보자</div></pre></td></tr></table></figure>
<p>Deployment를 자세히보자<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kubectl describe deployments</div></pre></td></tr></table></figure></p>
<p>보면 레이블이 있는것을 확인할 수 있는데 디플로이먼트는 저절로 레이블이 하나 생긴다.</p>
<p>레이블을 변경해보자<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ kubectl label pod $POD_NAME app=v1</div><div class="line">를 입력하여 레이블을 app=v1 으로 변경하고</div><div class="line"></div><div class="line">$ kubectl describe pods $POD_NAME</div><div class="line">을 입력하여 확인해보자.</div><div class="line"></div><div class="line">$ kubectl get pods -l app=v1</div><div class="line">을 입력하여 잘반영되었나 확인해보자</div></pre></td></tr></table></figure></p>
<p>서비스를 삭제해보자<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ kubectl delete service -l run=sangheonkim</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;도커툴박스설치&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.docker.com/toolbox/overview/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://docs.docker.com/toolbox/overvie
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>(K8s) 5. 여러 인스턴스를 실행하기. Scaling 하기</title>
    <link href="http://KKimSangHeon.github.io/2019/04/23/kubernetes5/"/>
    <id>http://KKimSangHeon.github.io/2019/04/23/kubernetes5/</id>
    <published>2019-04-23T12:08:06.000Z</published>
    <updated>2019-04-28T09:42:12.109Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Scaling"><a href="#Scaling" class="headerlink" title="Scaling"></a>Scaling</h4><p>애플리케이션 스케일링하기<br>이전 모듈에서 서비스를 만들고 퍼블릭하게 노출했다. 해당 디플로이멘트는 하나의 파드로 증가하도록 했다. 트래픽이 증가하면 사용자가 요구하는대로 어플리케이션을 실행할 필요 있다,.<br>스케일링은 디플러이먼트의 어플리케이션 replicas를 몇개할지 정하는것이다.</p>
<p>하나만 감싸고 있는 서비스를 여러노드에 거쳐 서비스를 스케일 아웃을 할 수 있다.<br>디플로이먼트를 스케일 아웃하면 신규 파드가 생성되어서 가용한 자원이 있는 노드에 스케줄된다. 스케일링 인은 파드개수를 줄이는것을 의미한다.</p>
<p>이는 또한 오토스케일링을 지원하기도 한다.(즉 들어오는 유동적으로 결정해주기도 함)<br>제로로 스케일링하는것도 가능한데 이는 디플로이먼트에 정의되어있는 파드를 모드 제거 하는것이다.</p>
<p>애플리케이션의 인스턴스를 복수로 구동하게 되면 트래픽을 해당 인스턴스 모두에 분산시킬 방법이 필요해진다. 서비스는 노출된 디플로이먼트의 모든 파드에 네트워크 트래픽을 분산시켜줄 통합된 로드밸런서를 갖는다. 서비스는 엔드포인트를 이용해서 구동중인 파드를 지속적으로 모니터링함으로써 가용한 파드에만 트래픽이 전달되도록 해준다.</p>
<p>일단 여러인스턴스가 실행되면 롤링 업데이트를 자동으로 할 수 있다.</p>
<p>kubectl get deployments<br>를 입력하여 디플로이 먼트 리스트를 보자<br>DESIRED는 설정에서 정의된 replicas 개수를 의미<br>CURRENT는 현재동작중인 개수<br>UP-TO-DATE 는 DESIRED를 맞추기 위해 뭐가 바뀌었는지<br>AVAILABLE 유저한테 가용할 수 있는 개수</p>
<p>replicas을 네개로 바꿔보자<br>kubectl scale deployments/kubernetes-bootcamp –replicas=4</p>
<p>kubectl get deployments<br>를 입력하여 4개가 도는지 확인해보자</p>
<p>파드는 각 다른 아이피를 갖는데<br>kubectl get pods -o wide<br>를 입력하여 4개에 대해 자세히 볼수 있다.</p>
<p>kubectl describe deployments/kubernetes-bootcamp<br>를 입력하여 변경사항을 기록한 로그를 확인할 수 있다.(replicas를 4개로 바꾼것 확인 가능)</p>
<p>kubectl describe services/kubernetes-bootcamp<br>를 입력하여 서비스가 어떤아이피로 제공하고 있는지 확인할 수 있다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template=&apos;&#123;&#123;(index .spec.ports 0).nodePort&#125;&#125;&apos;)</div><div class="line">echo NODE_PORT=$NODE_PORT</div></pre></td></tr></table></figure>
<p>를 입력하여 포트를 확인해보자.</p>
<p>이번엔 아래를 입력하여 스케일 다운해보자 replicas를2개로 바꾸자<br>kubectl scale deployments/kubernetes-bootcamp –replicas=2</p>
<p>kubectl get deployments<br>를 입력하여 디폴로이 먼트의 파드 개수를 확인해보자.</p>
<p>kubectl get pods -o wide<br>를 입력하여 2개의 파드가 종료된것을 확인할 수 있다.</p>
<h4 id="Rolling-update"><a href="#Rolling-update" class="headerlink" title="Rolling update"></a>Rolling update</h4><p>유저는 어플리케이션을 항상 사용할수 있도록 원한다. 그리고 개발자는 하루에 여러번 배포할 수 있길 바란다. 이를 쿠버네티스에서 제공한느 롤링 업데이트를 통해 할 수 있다. 이는 디플로이먼트를 제로다운타임으로 점진적으로 파드를 업데이트 할 수 있다. 새파드는 가용한 리소스를 사용하여 새로운 파드가 만들어질 수 있다.</p>
<p>이전에는 여러 인스턴스를 에서 스케일링하는것을 배웠다. 기본적으로, 업데이트가 이루어지는 동안 이용 불가한 파드의 최대 개수와 생성 가능한 새로운 파드의 최대 개수는 하나다. 두 옵션은 기본적으로 업데이트할 때 파드 개수만큼 한번에 꺼버릴수있다. 그리고 최대갯수만큼 파드를 생성할 수있다.(즉 비율을 적용하여 할 수 있다.) 쿠버네티스에서 업데이트는 버전으로 관리되고 어떠한 디플로이먼트 업데이트라도 이전버전으로 원복이 가능하다.</p>
<p>어플리케이션 스케일링과 비슷하게 디플로이먼트가 노출되어있으면 서비는 가용한 파드한테만 보낸다.<br>롤링업데이트는 다음과 같은 행동을 허용한다.</p>
<ul>
<li>어플리케이션 환경 변경(컨테이너 이미지 변경방법)</li>
<li>이전버전으로 롤백</li>
<li>CI/CD 제로다운타임으로</li>
</ul>
<p>새버전으로 업데이트 하고 롤백해보자</p>
<p> kubectl get deployments<br> 를 입력하여 디폴로이 먼트들을 확인해보자(4개가 떠있다)</p>
<p> kubectl get pods<br> 를 입력하여 돌아가고 있는 파드들을 보자</p>
<p>kubectl describe pods<br>를 입력하여  이미지 버전을 보자</p>
<p>이미지를 version2로 바꾸기 위해 다음을 입력하자</p>
<p>kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=jocatalin/kubernetes-bootcamp:v2</p>
<p>kubectl get pods<br>를 입력하면 4개는 종료하고 러닝은 4개인것을 볼 수 있다.<br>즉 한번에 4개를 죽여버리고 4개를 실행<br>제로 다운타임이 아니다!!</p>
<p>kubectl describe services/kubernetes-bootcamp<br>를 입력하여 앱이 돌아가고 있는것과 아이피 포트를 확인하자</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template=&apos;&#123;&#123;(index .spec.ports 0).nodePort&#125;&#125;&apos;)</div><div class="line">echo NODE_PORT=$NODE_PORT</div></pre></td></tr></table></figure>
<p>를 입력하여 포트 설정 후</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl $(minikube ip):$NODE_PORT</div></pre></td></tr></table></figure>
<p>을 입력하여 잘 돌고있나 보자</p>
<p>kubectl rollout status deployments/kubernetes-bootcamp<br>를 입력하여 롤 아웃된것을 확인할 수 있다</p>
<p>kubectl describe pods<br>를 입력하여 현재 이미지 버전을 볼 수 있다.</p>
<p>kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=gcr.io/google-samples/kubernetes-bootcamp:v10<br>를 입력하여 이미지를 버전 10으로 바꾸자</p>
<p>kubectl get deployments<br>를 입력하여 디플로이먼트의 현재상황을 보자<br>하나가 문제가 생긴것을 확인할 수 있다.</p>
<p>kubectl get pods<br>를 하면 파드들을 더 자세히 볼 수 있다.</p>
<p>kubectl describe pods<br>를 입력하여 파드들의 상태를 보자. 이미지가 바뀐지 보자<br>봤는데 이미지가 바뀌지 않은것을 확인할 수 있다.<br>레파지토리에 v10 이 없어서 그렇다. 그러므로 롤백하자.</p>
<p>kubectl get pods<br>를 입력하여 4개가 잘 돌고있는지 보고</p>
<p>kubectl describe pods<br>를 입력하여 이미지가 잘 돌고있는지 보자</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;Scaling&quot;&gt;&lt;a href=&quot;#Scaling&quot; class=&quot;headerlink&quot; title=&quot;Scaling&quot;&gt;&lt;/a&gt;Scaling&lt;/h4&gt;&lt;p&gt;애플리케이션 스케일링하기&lt;br&gt;이전 모듈에서 서비스를 만들고 퍼블릭하게 노출했다. 해당 디
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>(K8s) 4. 서비스를 사용하여 앱을 외부로 공개하기 , 서비스 / 레이블</title>
    <link href="http://KKimSangHeon.github.io/2019/04/23/kubernetes4/"/>
    <id>http://KKimSangHeon.github.io/2019/04/23/kubernetes4/</id>
    <published>2019-04-23T12:08:01.000Z</published>
    <updated>2019-04-23T12:18:16.726Z</updated>
    
    <content type="html"><![CDATA[<h4 id="서비스를-사용하여-앱을-외부로-공개하기"><a href="#서비스를-사용하여-앱을-외부로-공개하기" class="headerlink" title="서비스를 사용하여 앱을 외부로 공개하기"></a>서비스를 사용하여 앱을 외부로 공개하기</h4><p><a href="https://kubernetes.io/ko/docs/tutorials/kubernetes-basics/expose/expose-intro/" target="_blank" rel="external">https://kubernetes.io/ko/docs/tutorials/kubernetes-basics/expose/expose-intro/</a></p>
<p>지금까지의 앱은 컨테이너 안에서 도는데 private하고 네트웍도 isolate되어있었다. 그러므로 proxy 를 붙여서 동작했었다</p>
<h4 id="쿠버네티스-서비스에-대한-개요"><a href="#쿠버네티스-서비스에-대한-개요" class="headerlink" title="쿠버네티스 서비스에 대한 개요"></a>쿠버네티스 서비스에 대한 개요</h4><p>파드는 언젠가 죽는것이다. 즉 라이프사이클이 있다. 어떤 워커노드가 죽으면 그 노드에서 돌고있는 파드도 죽는다.<br> 그렇게되면 ReplicationController 가 클러스터를 동적으로 새로운노드를 만듬으로서 복구한다. 예를들어 이미지 처리하는 백엔드가 3개의 어플리케이션을 갖고있다 해보자. 프론트엔드는 백엔드 파드가 없어지는것 생기는것에 대해 신경쓰지 말고 동작하여야 한다. 각 파드는 유니크한 아이피를 갖고있는데 애플리케이션이 계속해서 동작할 수 있도록 발생하는 변화들을 서로 감지하는 방법이 필요하다.</p>
<h3 id="서비스"><a href="#서비스" class="headerlink" title="서비스"></a>서비스</h3><p>쿠버네티스에 있는 서비스는 파드의 set을 논리적으로 정의 한것이고 그 파드들에게 어떻게 접근할 수 있는지에 대한 정책을 정의한것이다.<br>서비스는 파드들간에 커플링을 낮춘다. 서비스는 모든 쿠버네티스 오브젝트들과 같이 YAML (보다 선호하는) 또는 JSON을 이용하여 정의되고. 서비스가 대상으로 하는 파드 셋은 보통 LabelSelector에 의해 결정된다</p>
<h4 id="서비스-외부로-노출하기"><a href="#서비스-외부로-노출하기" class="headerlink" title="서비스 외부로 노출하기"></a>서비스 외부로 노출하기</h4><p>비록 각각의 파드가 제각각의 IP를 갖고있지만 서비스 없이는 클러스터 바깥으로 노출되지 않는다. 서비스는 어플리케이션이 트래픽을 받게할 수 있는데 ServiceSpec에 type을 지정하여 노출 할 수 있다.</p>
<h4 id="ServiceSpec의-type"><a href="#ServiceSpec의-type" class="headerlink" title="ServiceSpec의 type"></a>ServiceSpec의 type</h4><ul>
<li>ClusterIP (기본값) - 클러스터 내에서 내부 IP 에 대해 서비스를 노출해준다. 이 방식은 오직 클러스터 내에서만 서비스가 접근될 수 있도록 해준다.</li>
<li>NodePort - NAT가 이용되는 클러스터 내에서 각각 선택된 노드들의 동일한 포트에 서비스를 노출시켜준다. <nodeip>:<nodeport>를 이용하여 클러스터 외부로부터 서비스가 접근할 수 있도록 해준다. CluserIP의 상위 집합이다.</nodeport></nodeip></li>
<li>LoadBalancer - (지원 가능한 경우) 기존 클라우드에서 외부용 로드밸런서를 생성하고 서비스에 고정된 공인 IP를 할당해준다. NodePort의 상위 집합이다.</li>
<li>ExternalName - 프록시를 사용하지 않고 임의의 Name을 사용해서 expose 하는방법으로 externalName을 스펙에다 정의함(YAML 혹은 JSON)  kube-dns 1.7 이상 요구됨</li>
</ul>
<p>추가적으로 셀렉터를 지정하지 않는경우도 있는데 셀렉터를 지정하지 않은것은 엔드포인트를 오브젝트를 만들지 않을것이다. 그렇게 함으로써 유저들로 하여금 직접 서비스를 특정엔드포인트에 매핑할 수 있도록 해준다. selector를 생략하게 되는 또 다른 가능성은 여러분이 type: ExternalName을 이용하겠다고 확고하게 의도하는 경우이다.</p>
<h4 id="서비스와-레이블"><a href="#서비스와-레이블" class="headerlink" title="서비스와 레이블"></a>서비스와 레이블</h4><p>서비스는 파드들의 묶음인데 하나의 ip로 묶인다. 하나의 아이피는 외부에 노출되어 서비스안에 존재하는 파드들에 접근할 수 있게해준다. 서비스는 파드셋에다가 트래픽을 라우팅(쿠버네티스 서비스들에 의해 처리된다.)하는데 서비스는 파드가 애플리케이션에 영향을 주지않고 혼자 죽거나 살아날 수 있도록 한다.</p>
<p>파드 셋을 label이랑 selector을 사용하여 매치한다. label은 key / value 쌍이며 오브젝트에 붙어있고 여러가지 방식으로 사용될 수 있다.</p>
<ul>
<li>개발, 테스트, 그리고 상용환경에 대한 객체들의 지정</li>
<li>임베디드된 버전 태그들</li>
<li>태그들을 이용하는 객체들에 대한 분류</li>
</ul>
<p>레이블은 오브젝트가 만들어 질때 붙일수도 있고 나중에 붙일수있고 아무때나 수정할 수 있다.</p>
<p>kubectl get pods<br>를 입력하고 파드들을 확인해보자.</p>
<p>kubectl get services<br>를 입력하여 서비스를 확인해보자. 만들지도 않았는데 하나가 돌아가고 있는데 클러스터에서 미니큐브를 만들면 실행되는것이다.</p>
<p>새로운 서비스를 만들고 노출하려면 다음과 노트 포트를 파라미터로 줘야한다.<br>kubectl expose deployment/kubernetes-bootcamp –type=”NodePort” –port 8080<br>내부 8080포트에 붙으라는것.</p>
<p>kubectl get services<br>를 입력하여 서비스를 확인해보자.<br>하나가 더 추가가 된것을 알 수 있다.</p>
<p>서비스가 클러스터ip로 인터널, external 포트가 있다.</p>
<p>kubectl describe services/kubernetes-bootcamp<br>를 입력하여 자세히 살펴보자.</p>
<p>노드포트라는 환경변수를 만들자<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template=&apos;&#123;&#123;(index .spec.ports 0).nodePort&#125;&#125;&apos;)</div><div class="line"></div><div class="line">echo NODE_PORT=$NODE_PORT</div></pre></td></tr></table></figure></p>
<p>아래를 입력하여 접근해보자<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl $(minikube ip):$NODE_PORT</div></pre></td></tr></table></figure></p>
<p>디플로이먼트는 자동으로 레이블이 하나있다.<br>이를통해 파드리스트를 쿼리해보자.<br>kubectl get pods -l run=kubernetes-bootcamp<br>run=kubernetes-bootcamp이 label이다.</p>
<p>kubectl get services -l run=kubernetes-bootcamp<br>를 입력하여 run=kubernetes-bootcamp 이라는 레이블을 갖고있는 서비스를 조회해보자.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export POD_NAME=$(kubectl get pods -o go-template --template &apos;&#123;&#123;range .items&#125;&#125;&#123;&#123;.metadata.name&#125;&#125;&#123;&#123;&quot;\n&quot;&#125;&#125;&#123;&#123;end&#125;&#125;&apos;)</div><div class="line">echo Name of the Pod: $POD_NAME</div></pre></td></tr></table></figure>
<p>를 입력하여 파드 네임을 환경변수에 넣어보자.</p>
<p>app=v1으로 새로운이름을 주자.<br>kubectl label pod $POD_NAME app=v1</p>
<p>kubectl describe pods $POD_NAME<br>레이블 확인해보자.</p>
<p>kubectl get pods -l app=v1<br>바뀐 레이블로 파드를 조회해보자.</p>
<p>kubectl delete service -l run=kubernetes-bootcamp<br>를 입력하여 서비스를 삭제하자.</p>
<p>kubectl get services<br>서비스를 확인해보자.</p>
<p>라우팅도 잘 안되나 확인해보자.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl $(minikube ip):$NODE_PORT</div></pre></td></tr></table></figure></p>
<p>파드안에서 동작하는 아래의 명령어를 통해 아직 파드가 동작는지 보자.<br>kubectl exec -ti $POD_NAME curl localhost:8080</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;서비스를-사용하여-앱을-외부로-공개하기&quot;&gt;&lt;a href=&quot;#서비스를-사용하여-앱을-외부로-공개하기&quot; class=&quot;headerlink&quot; title=&quot;서비스를 사용하여 앱을 외부로 공개하기&quot;&gt;&lt;/a&gt;서비스를 사용하여 앱을 외부로 공개하기&lt;/
    
    </summary>
    
      <category term="CS" scheme="http://KKimSangHeon.github.io/categories/CS/"/>
    
      <category term="MSA" scheme="http://KKimSangHeon.github.io/categories/CS/MSA/"/>
    
    
      <category term="kubernetes" scheme="http://KKimSangHeon.github.io/tags/kubernetes/"/>
    
  </entry>
  
</feed>
